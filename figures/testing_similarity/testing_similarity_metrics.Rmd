---
title: "Testing similarity metrics"
output: github_document
---

Code in this folder generates supplementary figures, involved with testing metrics for evaluating ALFA-K performance. Details in .Rmd file

```{r,setup,echo=F}
knitr::opts_knit$set(root.dir="~/projects/008_birthrateLandscape/ALFA-K/")
```




```{r,echo=FALSE,eval=FALSE,include=FALSE}

source("utils/landscape_functions.R")
source("utils/ALFA-K.R")
source("utils/comparison_functions.R")
library(ggplot2)
library(fields)
```

```{r,echo=FALSE,eval=FALSE,include=FALSE}
source("figures/testing_similarity/eval_comparison_metrics.R") 
```

We developed a number of metrics to evaluate the accuracy of fitness landscapes generated by ALFA-K. Metrics were developed using ALFA-K fits to data from simulations, so that ground truth fitnesses would be available from the GRF artificial landscapes. Across all fits we saw a Pearson correlation median 0.83 between predicted and true fitness. Accuracy was positively correlated with the number of sample timepoints (Fig. S1A) and with $\lambda$ (Fig. S1B), was negatively correlated with distance from frequent karyotypes (Fig. S1C), but had little correlating with the frequency threshold - a hyperparameter used in fitting (Fig. S1D). ALFA-K did fail to produce accurate fits in some cases (Fig. S1E). Our main concern was to design metrics to identify such instances, for applications where no ground truth fitness estimates will be available. 


![Figure S1. A-D) Pearson correlation coefficient of ALFA-K estimated fitness with ground truth fitness, grouped by A) Distance of karyotype from the nearest 'frequent karyotype' estimated in step 1 of the fit; B) Number of longitudinal samples used to train ALFA-K; C) frequency threshold for frequent karyotypes; D) GRF wavelength parameter $\lambda$. E) Pearson coefficients between actual fitness and ALFA-K estimated fitness of karyotypes.](figs/R2_analysis.png)   

   

We employed a leave-one-out cross validation procedure to test the ability of ALFA-K to estimate the fitness of karyotypes not present in the input data (Fig. S2). The fitness estimates from the first step of the ALFA-K pipeline (based on frequency changes of common karyotypes) are treated as "ground truth" and used as inputs for the cross validation test. 

![Figure S2 A) A simplified hypothetical example in which the fitness of a karyotype depends on the copy number of a single chromosome. B) In the cross validation procedure, each data-point is omitted from the training set in turn. The model is trained on the reduced dataset and then used to predict the fitness of the omitted clone. C) Cross validation predicted fitnesses are compared to the ground truth. ](figs/R2_demo.png)  



The cross validation metric performed extremely well at filtering out poor fits, with almost no fits having a positive $R^2$ but negatively correlating with the ground truth. However, the metric was perhaps overzealous in the sense that many simulations scored poorly despite having predicted fitnesses that correlated extremely strongly with the ground truth (it would be nice to explain why this happens, but I can't figure out why). 


We also sought to identify metrics based on the combined ability of the ABM and ALFA-K to predict future karyotype population evolution. We developed and tested two metrics: the Wasserstein metric, and the angle metric. Suppose two initially indentical karyotype populations evolve independently across two fitness landscapes, which could be either identical, or different (as shown, Fig. S3A-B). Two vectors are computed connecting the centroid of the initial population to the centroids of each of the evolved populations (Fig. S3C). The angle metric is the angle between these two vectors. Alternatively the Wasserstein distance between the two evolved populations can be computed (Fig. S3D, $d_3$). If the populations are evolving slowly relative to the timescale of measurement, the distance $d_3$ will automatically be low. Therefore we normalise by the mean distance each population has travelled from the founder, giving the Wasserstein metric $M_w=2d_3(d1+d2)^{-1}$.

![Figure S3. Metrics comparing similarity of population evolution. A-B) Examples of an initially identical founder population (black) evolving on two different landscapes. C) The vector angle between the centroids of the two evolved populations gives the angle metric. D) The Wasserstein metric is computed as the Wasserstein distance between the two evolved populations ($d_3$) normalised by the average distance the populations have travelled ($d_1$,$d_2$). ](figs/metric_example.png)   



To aid intepretation of the Wasserstein and angle metrics, we generated pairs of vectors uniformly distributed on the surface of the 22-dimensional hypersphere and computed the values of the metrics for each vector pair (Fig. S4). The expected value of the angle metric was $90^{\circ}$ while the Wasserstein metric was $\sqrt{2}$. Therefore one can say that recovering values less than these thresholds indicates better agreement than random chance. 

![Figure S4. Metric expectation. Pairs of vectors were generated uniformly on the surface of a 22-dimensional hypersphere. The distribution of A) angles, and B) distances between each pair of vectors is shown. ](figs/metric_insights.png)  

  

We tested the ability of each metric to characterise whether an ALFA-K estimated landscape was accurate or not. We applied the $R^2$ metric to ALFA-K landscapes fit to data from our ABM test simulations. These fitted landscapes were also used as input to a second round of ABM simulations, to which we applied the angle and Wasserstein metrics. All three metrics were able to  discriminate between landscapes that correlated strongly with the ground truth and those that did not.     

 

![Figure S5. Evaluation of metrics. A-C) The mean value of Pearson correlation between ground truth and ALFA-K fitted landscape, for corresponding values of A) angle metric, B) Wasserstein metric, and C) $R^2$ metric. D-F) Comparison of Pearson correlation and D) angle metric, E) Wasserstein metric, and F) $R^2$ metric for all fitted landscapes. ](figs/metric_tests.png) 
 



```{r,echo=FALSE,eval=FALSE,include=FALSE}

y <- readRDS("figures/alfak_ABM_tests/data/fit_summary_info.Rds")

x <- readRDS("figures/alfak_ABM_tests/data/loo_summaries.Rds")
#x2 <- readRDS("figures/testing_similarity/metrics.Rds")
ids <- data.frame(do.call(rbind,lapply(x$rep, function(i) unlist(strsplit(i,split="_"))[c(4,6,8)])))
colnames(ids) <- c("wavelength","misrate","rep2")
x <- cbind(x,ids)

x <- split(x,f=interaction(x$ntp,x$minobs,x$rep))
xl <- x
df <- do.call(rbind,lapply(x,function(xi){
  
  dfi <- xi
  
dfi$cor <- tryCatch(R2(xi$pred[!is.na(xi$pred)],xi$f_est[!is.na(xi$pred)]),
                    error=function(e) return(NaN))
return(dfi[1,-c(1,2)])
}))
colnames(df)[c(3,ncol(df))] <- c("id1","R2")
df$id2 <- paste0("minobs_",df$minobs,"_ntp_",df$ntp,"_00000.Rds")

x <- merge(y,df)
df <- x
x <- x[,-c(1,2)]
x$R2[x$R2<(-1)]<- -1

z <- x[x$id=="fq",]

x <- x[!x$wavelength=="0p1",]

sdf <- reshape2::melt(table(x$wavelength)/(3*9*100))

hist(x$cor)

sem <- function(x) sd(x[!is.na(x)])/sqrt(sum(!is.na(x)))

di <- aggregate(list(mean=x$cor),by=list(id=x[,"id"]),mean,na.rm=T)
di$sem <- aggregate(list(sem=x$cor),by=list(id=x[,"id"]),sem)$sem
di$id <- c('fq'=0,'n2'=2,'nn'=1)[di$id]

p3 <- ggplot(di,aes(x=id,y=mean))+
  geom_col(fill="grey70",color="black")+
  geom_errorbar(aes(ymin=mean-sem,ymax=mean+sem))+
  scale_x_continuous("distance")+
  scale_y_continuous("mean Pearson")+
  labs(tag="C")+
  theme_classic(base_size=8)
p3

di <- aggregate(list(mean=x$cor),by=list(id=x[,"ntp"]),mean,na.rm=T)
di$sem <- aggregate(list(sem=x$cor),by=list(id=x[,"ntp"]),sem)$sem

p1 <- ggplot(di,aes(x=as.character(id),y=mean))+
  geom_col(fill="grey70",color="black")+
  geom_errorbar(aes(ymin=mean-sem,ymax=mean+sem))+
  scale_x_discrete("training samples")+
  scale_y_continuous("mean Pearson")+
  labs(tag="A")+
  theme_classic(base_size=8)
p1

di <- aggregate(list(mean=x$cor),by=list(id=x[,"minobs"]),mean,na.rm=T)
di$sem <- aggregate(list(sem=x$cor),by=list(id=x[,"minobs"]),sem)$sem

p4 <- ggplot(di,aes(x=as.character(stringr::str_pad(id,width=2)),y=mean))+
  geom_col(fill="grey70",color="black")+
  geom_errorbar(aes(ymin=mean-sem,ymax=mean+sem))+
  scale_x_discrete("frequency threshold")+
  scale_y_continuous("mean Pearson")+
  labs(tag="D")+
  theme_classic(base_size=8)
p4

di <- aggregate(list(mean=x$cor),by=list(id=x[,"wavelength"]),mean,na.rm=T)
di$sem <- aggregate(list(sem=x$cor),by=list(id=x[,"wavelength"]),sem)$sem

p2 <- ggplot(di,aes(x=gsub("p",".",id),y=mean))+
  geom_col(fill="grey70",color="black")+
  geom_errorbar(aes(ymin=mean-sem,ymax=mean+sem))+
  scale_x_discrete(expression(lambda))+
  scale_y_continuous("mean Pearson")+
  labs(tag="B")+
  theme_classic(base_size=8)
p2







p5 <- ggplot(x,aes(x=cor))+
  facet_grid(cols=vars(paste0("lambda==",gsub("p",".",wavelength))),
             rows=vars(paste0(ntp,"~samples")),
             labeller="label_parsed")+
  geom_histogram(binwidth=0.2)+
  scale_x_continuous("Pearson coefficient")+
  scale_y_continuous("count")+
  labs(tag="E")+
  theme_bw(base_size = 8)


library(gridExtra)

plt_top <- grid.arrange(grobs=list(p1,p2,p3,p4),ncol=2,nrow=2)
plt <- grid.arrange(grobs=list(plt_top,p5),ncol=2,nrow=1,widths=c(2,3))

ggsave("figures/testing_similarity/figs/R2_analysis.png",plot=plt,width=8,height=3,units="in")
```


```{r,echo=FALSE,eval=FALSE,include=FALSE}
## xv metric explanation
library(fields)
set.seed(42)
x <- 1:8
y <- dnorm(x,mean=4.3,sd=2)+rnorm(length(x),mean=0,sd=0.02)

est <- lapply(x,function(i){
  mod <- smooth.spline(x=x[-i],y = y[-i],spar=0.4)
  predict(mod,x)$y
})

sel <- 3
df1 <- data.frame(x,y,sel="train")
df1$sel[sel] <- "test"
df2 <- data.frame(x,y=est[[3]])
df3 <- data.frame(y,yest=sapply(1:length(est),function(i) est[[i]][i]))

pa <- ggplot(df1,aes(x=x,y=y))+
  geom_point()+
  scale_x_continuous("copy number")+
  scale_y_continuous("fitness")+
  theme_classic(base_size=8)+
  labs(tag="A")

pb <- ggplot(df1,aes(x=x,y=y))+
  geom_point(aes(color=sel))+
  geom_line(data=df2,aes(linetype="prediction"))+
  scale_x_continuous("copy number")+
  scale_y_continuous("fitness")+
  theme_classic(base_size=8)+
  labs(tag="B")+
  scale_color_discrete("")+
  scale_linetype_discrete("")

pc <- ggplot(df3,aes(x=y,y=yest))+
  geom_point()+
  geom_abline()+
  scale_x_continuous("ground truth ")+
  scale_y_continuous("estimated fitness")+
  theme_classic(base_size=8)+
  labs(tag="C")

plt <- grid.arrange(grobs=list(pa,pb,pc),ncol=3,nrow=1,widths=c(3,4,3))
ggsave("figures/testing_similarity/figs/R2_demo.png",plot=plt,width=8,height=2,units="in")
```


```{r,echo=FALSE,eval=FALSE,include=FALSE}
landcontours <- function(seed=42,nchrom=2,Nwaves=10,wavelength=0.8){
  set.seed(seed)
  pk <- gen_rf_landscape(founder = sample(1:10,nchrom,replace = T),Nwaves = Nwaves,wavelength = wavelength)
  mat <- expand.grid(x1=seq(2.5,6,0.1),x2=seq(2,5,0.1))
  f <- apply(mat,1,function(xi) get_rf_fitness(k=xi,pk=pk,wavelength=wavelength))
  data.frame(cbind(mat,f))
}

source("utils/landscape_functions.R")


df1 <- landcontours(seed=42)
df2 <- landcontours(seed=3)

x0 <- data.frame(x1=rnorm(10,mean=3.5,sd=.2),x2=rnorm(10,mean=3.5,sd=0.2))
x1 <- data.frame(x1=rnorm(10,mean=5.3,sd=.2),x2=rnorm(10,mean=4,sd=0.2))
x2 <- data.frame(x1=rnorm(10,mean=3.3,sd=.2),x2=rnorm(10,mean=2.3,sd=0.2))

condf <- data.frame(xstart=c(3.5,3.5),xend=c(5.3,3.3),
                     ystart=c(3.5,3.5),yend=c(4,2.3))
angles <- with(condf, atan2(xend - xstart, yend - ystart))
## split into 2:
pa <- ggplot(df1, aes(x1, x2))+ 
  geom_contour_filled(aes(z=f),show.legend = F,alpha=0.8)+
      geom_point(data=x0)+
  geom_point(data=x1,color="red")+
  theme_classic()+
  scale_x_continuous(limits=range(df1$x1))+
  scale_y_continuous(limits=range(df1$x2))+
  labs(tag="A")+
  theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())


pb <- ggplot(df2, aes(x1, x2))+ 
  geom_contour_filled(aes(z=f),show.legend = F,alpha=0.8)+
    geom_point(data=x0)+
  geom_point(data=x2,color="blue")+
  theme_classic()+
  labs(tag="B")+
  scale_x_continuous(limits=range(df1$x1))+
  scale_y_continuous(limits=range(df1$x2))+ theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())


txtdf <- data.frame(x=4,y=3,lab="theta")
pc <- ggplot(df2)+ 
  #geom_contour(aes(z=f),color="white")+
  geom_point(data=x0,aes(x=x1, y=x2))+
  geom_point(data=x1,aes(x=x1, y=x2),color="red")+
  geom_point(data=x2,aes(x=x1, y=x2),color="blue")+
  geom_segment(data=condf,aes(x=xstart,y=ystart,xend=xend,yend=yend))+
  geom_arc(aes(x0=3.5,y0=3.5,r=0.5,start=angles[1],end=2*pi+angles[2]))+
  geom_text(data=txtdf,aes(x=x,y=y,label=lab),parse=TRUE)+
  theme_classic()+
  labs(tag="C")+
  scale_x_continuous(limits=range(df1$x1))+
  scale_y_continuous(limits=range(df1$x2))+ theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())


txtdf2 <- data.frame(x=c(3.5,4,4.5),y=c(3,4,3),lab=c("d[1]","d[2]","d[3]"))
condf2 <- data.frame(xstart=c(3.5,3.5,5.3),xend=c(5.3,3.3,3.3),
                     ystart=c(3.5,3.5,4),yend=c(4,2.3,2.3))
pd <- ggplot(df2)+ 
  geom_point(data=x0,aes(x=x1, y=x2))+
  geom_point(data=x1,aes(x=x1, y=x2),color="red")+
  geom_point(data=x2,aes(x=x1, y=x2),color="blue")+
  geom_segment(data=condf2,aes(x=xstart,y=ystart,xend=xend,yend=yend))+
  geom_text(data=txtdf2,aes(x=x,y=y,label=lab),parse=TRUE)+
  theme_classic()+
  labs(tag="D")+
  scale_x_continuous(limits=range(df1$x1))+
  scale_y_continuous(limits=range(df1$x2))+ theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())


library(gridExtra)
plt <- grid.arrange(grobs=list(pa,pb,pc,pd))
ggsave("figures/testing_similarity/figs/metric_example.png",plot=plt,width=6,height=4,units="in")

```

```{r,echo=FALSE,eval=FALSE,include=FALSE}

find_r2 <- function(x){
  x <- split(x,f=interaction(x$ntp,x$minobs,x$rep))
  xl <- x
  df <- do.call(rbind,lapply(x,function(xi){
  
  dfi <- xi
  
  k <- do.call(rbind,lapply(rownames(dfi),s2v))
  k[,22] <- as.numeric(substr(k[,22],0,1))
  d <- apply(as.matrix(dist(k,method = "manh")),1,function(ki){
    min(ki[ki>0])
  })
  
  xi$pred[d>2] <- NaN
  
  dfi$R2 <- tryCatch(R2(xi$pred[!is.na(xi$pred)],xi$f_est[!is.na(xi$pred)]),
                    error=function(e) return(NaN))
  dfi$R2[dfi$R2<(-1)]<- -1
  return(dfi[1,-c(1,2)])
  }))

rownames(df) <- NULL
return(df)

}


y <- readRDS("figures/alfak_ABM_tests/data/fit_summary_info.Rds")
xv <- readRDS("figures/alfak_ABM_tests/data/loo_summaries.Rds")
x <- readRDS("figures/testing_similarity/fitted_abm_run_metrics.Rds")

xv <- find_r2(xv)
xv$id2 <- paste0("minobs_",xv$minobs,"_ntp_",xv$ntp)
colnames(xv)[3] <- "id1"

y$id2 <- sapply(y$id2, function(yi){
  paste(head(unlist(strsplit(yi,split="_")),4),collapse = "_")
})
x$id2 <- sapply(x$id2, function(yi){
  paste(head(unlist(strsplit(yi,split="_")),4),collapse = "_")
})


z <- merge(x,y,by = c("id1","id2"))
z <- merge(xv,z,by = c("id1","id2"))


z$wavelength <- sapply(z$id1, function(i){
  unlist(strsplit(i,split="_"))[4]
})


z <- z[z$wavelength!="0p1",]
z1 <- aggregate(list(a_2500=z$a_2500),
                by=list(ntp=z$ntp,minobs=z$minobs,
                        wavelength=z$wavelength,cor=z$cor,
                        id=z$id,R2=z$R2),
                mean,na.rm=T)
z1$w_2500 <- aggregate(list(w_2500=z$w_2500),
                by=list(ntp=z$ntp,minobs=z$minobs,
                        wavelength=z$wavelength,cor=z$cor,
                        id=z$id,R2=z$R2),
                mean,na.rm=T)$w_2500
zz <- z
z <- z1

ai <- round(z$a_2500/10)
ca <- aggregate(list(cor=z$cor),by=list(M=10*ai),mean,na.rm=T)
ca$metric <- "angle"

wi <- round(z$w_2500*10)
cw <- aggregate(list(cor=z$cor),by=list(M=wi/10),mean,na.rm=T)
cw$metric <- "Wasserstein"

ri <- round(z$R2*10)
cr <- aggregate(list(cor=z$cor),by=list(M=ri/10),mean,na.rm=T)
cr$metric <- "R2" 

cdf <- rbind(ca,cw,cr)

pa <- ggplot(ca,aes(x=M,y=cor))+
  geom_point()+
  scale_y_continuous("Pearson coefficient")+
  scale_x_continuous("angle metric")+
  geom_vline(xintercept=90,color="red",linetype=2)+
  theme_classic(base_size=8)+
  labs(tag="A")

pb <- ggplot(cw,aes(x=M,y=cor))+
  geom_point()+
  scale_y_continuous("Pearson coefficient")+
  scale_x_continuous("Wasserstein metric")+
  geom_vline(xintercept=sqrt(2),color="red",linetype=2)+
  theme_classic(base_size=8)+
  labs(tag="B")

pc <- ggplot(cr,aes(x=M,y=cor))+
  geom_point()+
  scale_y_continuous("Pearson coefficient")+
  scale_x_continuous(expression(R^2~metric))+
  geom_vline(xintercept=0,color="red",linetype=2)+
  theme_classic(base_size=8)+
  labs(tag="C")

pd <- ggplot(z[z$id=="n2",],aes(x=a_2500,y=cor))+
  geom_point(alpha=0.1)+
  scale_y_continuous("Pearson coefficient")+
  scale_x_continuous("angle metric")+
  geom_vline(xintercept=90,color="red",linetype=2)+
  theme_classic(base_size=8)+
  labs(tag="D")

pe <- ggplot(z[z$id=="n2",],aes(x=w_2500,y=cor))+
  geom_point(alpha=0.1)+
  scale_y_continuous("Pearson coefficient")+
  scale_x_continuous("Wasserstein metric")+
  geom_vline(xintercept=sqrt(2),color="red",linetype=2)+
  theme_classic(base_size=8)+
  labs(tag="E")

pf <- ggplot(z[z$id=="n2",],aes(x=R2,y=cor))+
  geom_point(alpha=0.1)+
  scale_y_continuous("Pearson coefficient")+
  scale_x_continuous(expression(R^2~metric))+
  geom_vline(xintercept=0,color="red",linetype=2)+
  theme_classic(base_size=8)+
  labs(tag="F")


library(gridExtra)
plt <- grid.arrange(grobs=list(pa,pb,pc,pd,pe,pf),ncol=3)
ggsave("figures/testing_similarity/figs/metric_tests.png",plot=plt,width=6,height=4,units="in")

```

```{r,echo=FALSE,eval=FALSE,include=FALSE}

uhypoint <- function(n,r){
  v <- rnorm(n)
  r*v/sqrt(sum(v^2))
}
d1 <- 1
d2 <- 1
dftest <- do.call(rbind,lapply(1:5000,function(i){
  v1 <- uhypoint(22,d1)
  v2 <- uhypoint(22,d2)
  
  data.frame(a=getangle(v1,v2),
             d=2*sqrt(sum((v1-v2)^2))/(d1+d2))
  
}))

dftest1 <- reshape2::melt(dftest)

pa <- ggplot(dftest1[dftest1$variable=="a",],aes(x=value))+
  geom_histogram(binwidth=10)+
  scale_x_continuous("angle")+
  theme_classic(base_size=8)+
  geom_vline(xintercept=90,color="red",linetype=2)+
  labs(tag="A")

pb <- ggplot(dftest1[dftest1$variable=="d",],aes(x=value))+
  geom_histogram(binwidth=0.1)+
  scale_x_continuous("Euclidean distance")+
  theme_classic(base_size=8)+
  geom_vline(xintercept=sqrt(2),color="red",linetype=2)+
  labs(tag="B")

plt <- grid.arrange(grobs=list(pa,pb),ncol=2)
ggsave("figures/testing_similarity/figs/metric_insights.png",plot=plt,width=4,height=2,units="in")


```

