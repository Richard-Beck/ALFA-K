---
title: "README"
author: "Richard J Beck"
date: "`r Sys.Date()`"
output:
  md_document:
    variant: markdown_github
---

Fitting ALFA-K model to Salehi data

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/projects/008_birthrateLandscape/ALFA-K/")
```

First we will pull all the lineages from the metadata. A lineage is defined as any sequence of two or more consecutive samples. 
```{r}

m <- read.csv("data/salehi/metadata.csv")

lineage_wrapper <- function(ids){
  list(ids=ids)
}

lineage_generator <- function(uid){
  ids <- c()
  lineages <- list()
  while(!is.na(uid)){
    ids <- c(uid,ids)
    uid <- m$parent[m$uid==uid]
    if(length(ids)>1) lineages <- c(lineages,lineage_wrapper(ids))
  }
  return(lineages)
}

descendent_checker <- function(ids){
  dec1 <- m$uid[m$parent==tail(ids,1)&!is.na(m$parent)]
  dec2 <- m$uid[m$parent%in%dec1]
  list(ids=ids,dec1=dec1,dec2=dec2)
}

lineage_namer <- function(lineage){
  suffix <- paste0("_l_",length(lineage$ids),"_d1_",length(lineage$dec1),
                   "_d2_",length(lineage$dec2))
  id <- tail(lineage$ids,1)
  sid <- paste(gsub(" ", "", m$datasetname[id==m$uid],fixed = TRUE),m$timepoint[id==m$uid],sep = "_")
  sid <- gsub("/", "", sid,fixed = TRUE)
  paste0(sid,suffix)
}

lineages <- do.call(c,lapply(m$uid,lineage_generator))
lineages <- lapply(lineages, descendent_checker)

lnames <- sapply(lineages,lineage_namer)
names(lineages) <- lnames
saveRDS(lineages,"figures/salehi_data_fitting/lineages.Rds")

```

Run the following scripts (in order) to preprocess & fit the Salehi data.The third script will take several hours on a regular PC. 
```{r,eval=F}
source("figures/salehi_data_fitting/extract_cn_profiles.R")
source("figures/salehi_data_fitting/extract_lineage_v2.R") 
source("figures/salehi_data_fitting/fit_alfak_v2.R")
```

```{r,message=F,warning=F}
library(gtable)
library(ape)
library(ggtree)
library(treeio)
library(ggplot2)
library(xlsx)
source("utils/ALFA-K.R")
source("utils/comparison_functions.R")

lineage_info <- function(ln){
  treat_numeric <- c(n=0,y=1)
  has_descendents <- length(ln$dec1)>0
  has_parents <- sum(is.na(m$parent[m$uid%in%ln$ids]))==0
  treatments <- m$on_treatment[m$uid%in%ln$ids]
  nChanges <- sum(abs(diff(treat_numeric[treatments])))
  treatment_status <- "mixed"
  if(mean(treatments=="n")==1) treatment_status <- "off"
  if(mean(treatments=="y")==1) treatment_status <- "on"
  id <- tail(ln$ids,1)
  cellLine <- m$PDX_id[m$uid==id]
  sid <- paste(gsub(" ","", m$label[id==m$uid],fixed = TRUE),
               m$timepoint[id==m$uid],sep = "_")
  data.frame(id=sid,cellLine,has_descendents,has_parents,nChanges,treatment_status)
  
}

longest_cons <- function(ff,longest=T){
  ids <- sapply(ff, function(fi){
    paste(head(unlist(strsplit(fi,split="_")),2),collapse="_")
  })
  ff <- split(ff,f=ids)
  
  ff <- sapply(ff, function(fi){
    fi <- fi[order(fi)]
    if(longest) return(tail(fi,1))
    return(head(fi,1))
  })
  as.character(ff)
}
```


Results of ALFA-K across all possible lineages

NOTE: NaN values in the cross validation represent instances where the neighbour fitness estimation step cannot be correctly performed (due to not enough karyotypes in the input).

```{r}
source("utils/comparison_functions.R")

lineage_info <- function(ln){
  treat_numeric <- c(n=0,y=1)
  has_descendents <- length(ln$dec1)>0
  has_parents <- sum(is.na(m$parent[m$uid%in%ln$ids]))==0
  treatments <- m$on_treatment[m$uid%in%ln$ids]
  nChanges <- sum(abs(diff(treat_numeric[treatments])))
  treatment_status <- "mixed"
  if(mean(treatments=="n")==1) treatment_status <- "off"
  if(mean(treatments=="y")==1) treatment_status <- "on"
  id <- tail(ln$ids,1)
  sid <- paste(gsub(" ","", m$label[id==m$uid],fixed = TRUE),
               m$timepoint[id==m$uid],sep = "_")
  data.frame(id=sid,has_descendents,has_parents,nChanges,treatment_status)
  
}


get_r2 <- function(id,mo){
  x <- readRDS(paste0(dir,mo,"/",id,"."))
  xvr <- x$xv_res
  maxf <- max(xvr$f_est)
  xvr <- xvr[!is.na(xvr$f_xv),]
  r2 <- R2(obs = xvr$f_xv,pred=xvr$f_est)
  id <- unlist(strsplit(id,split=".Rds"))[1]
  id <- unlist(strsplit(id,split="_"))
  if(length(id)>8){
    idt <- tail(id,7)
    idh <- head(id,length(id)-7)
    idh <- paste(idh,collapse="_")
    id <- c(idh,idt)
  }
  mo <- tail(unlist(strsplit(mo,split="_")),1)
  res <- c(id[c(1,2,4,6,8)],mo,maxf,r2)
  names(res) <- c("datasetname","timepoint","samples","dec1","dec2","min_obs","maxf","r2")
  return(res)
}

m <- read.csv("data/salehi/metadata.csv")
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
linfo <- do.call(rbind,lapply(lineages,lineage_info))
linfo$filenames <- paste0(rownames(linfo),".Rds")
rownames(linfo) <- linfo$filenames
dir <- "data/salehi/alfak_fits/"
min_obs <- list.files(dir)

x <- lapply(min_obs, function(mo){
  ff <- list.files(paste0(dir,mo))
  ff <- ff[ff%in%linfo$filenames]
  res <- data.frame(do.call(rbind,lapply(ff,get_r2,mo=mo)))
  res <- cbind(res,linfo[ff,])
  
})

x <- data.frame(do.call(rbind,x))
rownames(x) <- NULL
x <- x[,!colnames(x)%in%c("datasetname","timepoint")]
x$r2 <- as.numeric(x$r2)
x$maxf <- as.numeric(x$maxf)

x$r2[x$r2<(-1)] <- -1
x <- x[order(x$r2,decreasing=T),]

saveRDS(x,"figures/salehi_data_fitting/fit_summaries.Rds")

```


```{r}
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[x$min_obs==5,]
p <- ggplot(x,aes(x=stringr::str_pad(samples,width = 2),y=r2))+
  #facet_grid(rows=vars(stringr::str_pad(min_obs,width = 2)))+
  geom_violin()+
  coord_flip()+
  scale_y_continuous(expression(cross~val.~R^2))+
  scale_x_discrete("samples in fit")
p
ggsave("figures/salehi_data_fitting/figures/xval_scores.png",width=3,height=3,units="in")
```

```{r}
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")

#x <- x[x$declevel==1,]

## untreated samples worked well - perhaps due to longer lineages?
x[!x$has_parents&!x$has_descendents&x$treatment_status=="off"&x$min_obs==5,]

## treated samples worked poorly - perhaps due to shorter lineages?
x[!x$has_descendents&x$treatment_status=="on"&x$min_obs==5,]

##samples amenable to forward prediction tests:
nrow(x[x$has_descendents&x$min_obs==5,])






##"core" samples
xl <- x[!x$has_descendents&x$min_obs==5,]
xl_on <- xl[xl$treatment_status=="on",]
xl_off <- xl[xl$treatment_status!="on",]
xl <- xl[xl$filenames%in%c(longest_cons(xl_off$filenames),longest_cons(xl_on$filenames)),]
xl <- xl[xl$filenames%in%longest_cons(xl$filenames,longest=F),]

## interestingly, I think if you look at the treated lineages you get better R^2 if you bunch treated/untreated passages than if you focus exclusively on treated passages. Apparently having more passages makes up for the change in condition. Perhaps it would be better to use these as our core samples? 
xl <- x[!x$has_descendents&x$min_obs==5,]
xl <- xl[xl$filenames%in%longest_cons(xl$filenames),]

```
Roughness metric as a function of ploidy.

```{r}
source("utils/landscape_functions.R")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
#x <- x[x$filenames%in%longest_cons(x$filenames),]
x <- x[x$r2>0.2,]
ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"
z <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  data.frame(id=fi,mean_f=mean(xi$xo$f_est),sd_f=sd(xi$xo$f_est))
}))
z$treatment_status <- x$treatment_status
z$id <- x$id
p <- ggplot(z,aes(x=id,y=sd_f,fill=treatment_status))+
  geom_col()+
  coord_flip()
p
#stop("comment me out to assess roughness")
y <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  r <- roughness_meas(xi,only_fq=T)
  r$id <- x$id[x$filenames==fi][1]
  return(r)
}))

ys <- split(y,f=y$id)
dfcor <- do.call(rbind,lapply(ys, function(yi){
  res <- cor.test(yi$ploidy,yi$roughness,method = "pearson")
  data.frame(pval=res$p.value,pearson = res$estimate)
}))
dfcor$id <- rownames(dfcor)
p <- ggplot(dfcor,aes(x=id,y=pearson,fill=pval))+
  geom_col()+
  coord_flip()+
  scale_fill_viridis_c("p value",trans="log",direction = -1)+
  scale_x_discrete("")+
  scale_y_continuous("pearson correlation coefficient")
p
ggsave("figures/salehi_data_fitting/figures/rougness_metric_correlation.png",width=6,height=5,units="in")



```
Moran metric as a function of ploidy.

```{r}
source("utils/landscape_functions.R")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
x <- x[x$r2>0.2,]
ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"

y <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))$xo
  m <- moran_freq(rownames(xi),fitness = xi$f_est)
  m$id <- x$id[x$filenames==fi][1]
  return(m)
}))


ys <- split(y,f=y$id)
dfcor <- do.call(rbind,lapply(ys, function(yi){
  res <- cor.test(yi$ploidy,yi$Ii,method = "pearson")
  data.frame(pval=res$p.value,pearson = res$estimate)
}))
dfcor$id <- rownames(dfcor)
p <- ggplot(dfcor,aes(x=id,y=pearson,fill=pval))+
  geom_col()+
  coord_flip()+
  scale_fill_viridis_c("p value",trans="log",direction = -1)+
  scale_x_discrete("")+
  scale_y_continuous("pearson correlation coefficient")
p
ggsave("figures/salehi_data_fitting/figures/moran_metric_correlation.png",width=6,height=5,units="in")

p <- ggplot(y,aes(x=id,y=ploidy))+
  geom_violin()+
  coord_flip()+
    scale_x_discrete("")+
  scale_y_continuous("ploidy")
p

ggsave("figures/salehi_data_fitting/figures/ploidy_dist.png",width=4,height=5,units="in")

```


Correlation between fitnesses on different landscapes:

```{r}
source("utils/landscape_functions.R")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
#x <- x[x$filenames%in%longest_cons(x$filenames),]
x <- x[x$r2>0.2,]
ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"
z <- pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  xii <- gen_all_neighbours(rownames(xi$xo))
  fii <- predict(xi$fit,xii)
  names(fii) <- apply(fii,1,paste,collapse=".")
  fi0 <- xi$xo$f_est
  names(fi0) <- rownames(xi$xo)
  c(fi0,fii)
})

combns <- expand.grid(a=1:length(z),b=1:length(z))

combns$cc <- sapply(1:nrow(combns), function(i){
  za <- z[[combns$a[i]]]
  zb <- z[[combns$b[i]]]
  za <- za[names(za)%in%names(zb)]
  if(length(za)==0) return(NaN)
  zb <- zb[names(za)]
  cc <- cor(za,zb)
  return(cc)
})
combns$a <- x$id[combns$a]
combns$b <- x$id[combns$b]

p <- ggplot(combns,aes(x=a,y=b,fill=cc))+
  geom_raster()+
  scale_x_discrete("")+
  scale_y_discrete("")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  scale_fill_viridis_c("pearson\ncoefficient")
p
ggsave("figures/salehi_data_fitting/figures/inter_lineage_correlations.png",width=7,height=6,units="in")
```



Testing forward prediction accuracy:
```{r}
m <- read.csv("data/salehi/metadata.csv")
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
cnmat <- readRDS("data/salehi/chrom_level_cn.Rds")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
xf <- x[x$has_descendents&x$min_obs==5,]
ids <- as.character(sapply(xf$filenames,function(fi){head(unlist(strsplit(fi,split=".Rds")),1)}))
simdir <- "data/salehi/forward_sims_v2/minobs_5/"

tst <- which(ids%in%list.files(simdir))

df <- do.call(rbind,pbapply::pblapply(tst, function(i){
  si <- paste0(simdir,ids[i],"/output/00000/")
  xs <- proc_sim(si,times=seq(0,300,150))$x
  vs <- do.call(rbind,lapply(rownames(xs),s2v))
  li <- lineages[[ids[i]]]
  
  ## sim output population vectors
  csx <- colSums(xs)
  xs <- t(xs)%*%vs
  for(k in 1:nrow(xs)) xs[k,] <- xs[k,]/csx[k]
  target_library_ids <- m$library_ids[m$uid==tail(li$ids,1)]
  target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
  x0 <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
  
  dfi <- do.call(rbind,lapply(1:length(li$dec1), function(j){
    target_library_ids <- m$library_ids[m$uid==li$dec1[j]]
    target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
    xd <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
    
    angles <- apply(xs,1,function(xsi){
      a <- xsi-x0
      b <- xd-x0
      ai <- getangle(a,b)
      
    })
    names(angles) <- paste0("a",names(angles))
    df <- cbind(xf[i,],t(angles))
    df$descendent <- li$dec1[j]
    df$declevel <- 1
    return(df)
  }))
  if(length(li$dec2)>0){
    dfii <- do.call(rbind,lapply(1:length(li$dec2), function(j){
      target_library_ids <- m$library_ids[m$uid==li$dec2[j]]
      target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
      xd <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
      
      angles <- apply(xs,1,function(xsi){
        a <- xsi-x0
        b <- xd-x0
        ai <- getangle(a,b)
        
      })
      names(angles) <- paste0("a",names(angles))
      df <- cbind(xf[i,],t(angles))
      df$descendent <- li$dec1[j]
      df$declevel <- 2
      return(df)
    }))
    dfi <- rbind(dfi,dfii)
  }
  
  return(dfi)
  
}))

saveRDS(df,"figures/salehi_data_fitting/validation_summaries.Rds")

```

```{r}

wrap_res <- function(df){
  angle_data <- df[,paste0("a",seq(0,300,150))]
  df <- df[,!colnames(df)%in%paste0("a",seq(0,300,150))]
  df$angle <- angle_data$a150
  df$angle[df$declevel==2] <- angle_data$a300
  df$pos_r2 <- df$r2>0
  df$good_r2 <- df$r2>0.3
  return(df)
  
}

df <- wrap_res(readRDS("figures/salehi_data_fitting/validation_summaries.Rds"))
df$lab1 <- "R^2<0"
df$lab1[df$pos_r2] <- "R^2>0"
df$lab2 <- paste0("passage~",df$declevel)
p <- ggplot(df,aes(x=samples,y=angle))+
  facet_grid(cols=vars(lab1),rows=vars(lab2),labeller = label_parsed)+
  geom_violin()+
  scale_x_discrete("sampled timepoints in fit")+
  scale_y_continuous("angle metric")
p
ggsave("figures/salehi_data_fitting/figures/forward_predictions.png",width=5,height=4,units="in")
```



Test ability to identify clones that have not yet emerged

```{r}
m <- read.csv("data/salehi/metadata.csv")
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
cnmat <- readRDS("data/salehi/chrom_level_cn.Rds")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
xl <- x[x$has_descendents&x$min_obs==5,]
xl <- xl[xl$filenames%in%longest_cons(xl$filenames),]

ff <- xl$filenames

pvals <- do.call(rbind,pbapply::pblapply(ff, function(fi){
  
  id <- head(unlist(strsplit(fi,split=".Rds")),1)
  l <- lineages[[id]]

  target_library_ids <- m$library_ids[m$uid%in%l$dec1]
  target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
  x0 <- do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]]))
  x0 <- apply(x0,1,paste,collapse=".")
  x0 <- unique(x0)
  
  pop <- readRDS(paste0("data/salehi/alfak_inputs_v2/",fi))$x
fit <- readRDS(paste0("data/salehi/alfak_fits/minobs_5/",fi))$fit
candidates <- gen_all_neighbours(rownames(pop)[pop[,ncol(pop)]>0])
f <- c(predict(fit,candidates))
candidates <- apply(candidates,1,paste,collapse=".")
names(f) <- candidates

emerged <- x0[!x0%in%rownames(pop)]

f_emerged <- f[names(f)%in%emerged]
if(length(f_emerged)<2) return(data.frame(pval=NaN,delta_fitness=NaN))
f_unemerged <- f[!names(f)%in%emerged]

res <- t.test(f_unemerged,f_emerged)
data.frame(pval=res$p.value,delta_fitness=diff(res$estimate),row.names = NULL)
}))

pvals$r2 <- xl$r2

p <- ggplot(pvals,aes(x=r2,y=delta_fitness))+
  geom_point()+
  scale_x_continuous(expression(R^2~cross~validation))+
  scale_y_continuous(expression(Delta~fitness))
p
ggsave("figures/salehi_data_fitting/figures/emerging_karyotype_prediction.png",width=3,height=3,units="in")

```

It would be very interesting to compare how similar population evolution was in the instances where we have parallel evolution going on. 

The result is not as expected

```{r}
source("utils/comparison_functions.R")
x <- readRDS("data/salehi/chrom_level_cn.Rds")
m <- read.csv("data/salehi/metadata.csv")
m <- m[m$PDX_id=="SA609",]

nm <- table(m$parent)
nm <- names(nm)[nm>1]

l <- do.call(rbind,lapply(nm, function(ni) {
  children <- m$uid[m$parent==ni & !is.na(m$parent)]
  combos <- combn(1:length(children),2)
  cond_match <- apply(combos,2,function(ci){
    m$on_treatment[m$uid==children[ci[1]]]==m$on_treatment[m$uid==children[ci[2]]]
  })
  data.frame(parent=ni,child1=children[combos[1,]],
             child2=children[combos[2,]],cond_match)
}))

l <- cbind(l,data.frame(t(apply(l[,1:3],1,function(li){
  sapply(li, function(lij) m$library_ids[m$uid==lij])
}))))
colnames(l)[1:3] <- paste0("uid_",colnames(l)[1:3])



l$angles <- sapply(1:nrow(l), function(i){
  idpar <- unlist(strsplit(l$parent[i],split=";"))
  idc1 <- unlist(strsplit(l$child1[i],split=";"))
  idc2 <- unlist(strsplit(l$child2[i],split=";"))
  
  vpar <- colMeans(do.call(rbind,lapply(idpar,function(id) x[[id]])))
  vc1 <- colMeans(do.call(rbind,lapply(idc1,function(id) x[[id]])))-vpar
  vc2 <- colMeans(do.call(rbind,lapply(idc2,function(id) x[[id]])))-vpar
  
  getangle(vc1,vc2)
})


p <- ggplot(l,aes(x=angles))+
  facet_wrap(~cond_match)+
  geom_histogram(binwidth=10)
p

aggregate(l$angles,by=list(l$cond_match),mean)
```


Below is stuff for plotting the lineages

NEW (more lineages)

OLD
```{r}

plotmaker <- function(pdx,m){
  print(pdx)
  conds <- data.frame(id=c("A96146A","A96149B","A118833A","A110673B","A118862A",
                         "A96219B","A118845B","A98244A","A98256A","A98283A",
                         "A96162B"),
                    dt=c(5,5,15,15,15,15,15,15,15,15,15),
                    mintp=c(1,1,1,3,3,1,1,5,1,4,1))

z <- lapply(1:nrow(conds),function(i){
  mintp <- paste0("X",conds$mintp[i])
  id <- conds$id[i]
  sid <- paste(gsub(" ", "", m$label[grepl(id,m$library_ids)],fixed = TRUE),m$timepoint[grepl(id,m$library_ids)],sep = "_")
  sid <- gsub("/", "", sid,fixed = TRUE)
  
  uids <- c(m$uid[grepl(id,m$library_ids)],m$parent[grepl(id,m$library_ids)])
  
  while(!is.na(tail(uids,1))){
    uids <- c(uids,m$parent[m$uid==tail(uids,1)])
  }
  
  msel <- m[m$uid%in%uids,]

  if(msel$PDX_id[1]!=pdx) return(NULL)
    msel[msel$timepoint>=mintp,]
})

z <- z[!sapply(z,is.null)]

maxl <- max(sapply(z,nrow))

uids <- do.call(rbind,z)
uids <- unique(uids$uid)

d <- matrix(0,nrow=length(uids),ncol=length(z))
for(i in 1:length(z)){
  d[uids%in%z[[i]]$uid,i] <- 1 
}
for(i in 1:nrow(d)) d[i,] <- d[i,]/sum(d[i,])
d <- data.frame(d)



m <- read.csv("data/salehi/metadata.csv")
m <- m[m$PDX_id==pdx,]
m$on_treatment <- c(n="no",y="yes")[m$on_treatment]
m2 <- m[!is.na(m$parent),]

tr <- as.phylo(m2[,c("uid","parent")])
tr$edge.length <- rep(1,nrow(tr$edge))

x <- as_tibble(tr)
nodelablr <- x$node
names(nodelablr) <- x$label
x$on_treatment <- sapply(x$label,function(i){
  m$on_treatment[m$uid==i]
})
tr <- as.treedata(x)

ff <- cbind(node=nodelablr[as.character(uids)],d)
tmp <- reshape2::melt(ff,id.vars="node")

pies <- nodepie(ff,cols=2:(1+length(z)))
pies <- lapply(pies, function(g) g+scale_fill_viridis_d())

##create  a dummy data frame to generate a fillable legend

nodesz <- .32#0.2*maxl/8
if(pdx=="SA609") nodesz <- 0.25
if(pdx=="SA906") nodez <- 0.4
df2 <- data.frame(x=rep(Inf,length(z)),
                  y=rep(Inf,length(z)),
                  z=paste0("X",1:length(z)))

p <- ggtree(tr)+ 
  geom_point(data=df2,aes(x=x,y=y,fill=z,linetype=NULL),shape=21)+
    aes(linetype=on_treatment)+
    #geom_nodepoint()+
  geom_inset(pies, width = nodesz, height = nodesz, x = "node")+
  ggtitle(pdx)+
  scale_linetype_discrete("on treament")+
  scale_fill_viridis_d("lineage")
p
}

```
```{r}
m <- read.csv("data/salehi/metadata.csv")
pdx <- c("SA906","SA609","SA1035","SA535")#,"SA532")
x <- lapply(pdx,plotmaker,m=m)
#x
#p <- cowplot::plot_grid(x[[1]],x[[2]],x[[3]],x[[4]],ncol=2)
```
http://127.0.0.1:32487/graphics/plot_zoom_png?width=632&height=314


Can we predict emergent karyotypes?
```{r}
library(ggrepel)
new_kary_predictions <- function(fi){
  
x <- readRDS(paste0(dir,fi))
x <- getBest(x)
if(is.null(x)) return(NULL)
ddir <- "data/salehi/alfak_inputs/"
d <- readRDS(paste0(ddir,fi))

gn_1 <- d$x[,ncol(d$x)-1]
gn <- d$x[,ncol(d$x)]

g_new <- gn[gn>0 & rowSums(d$x[,-ncol(d$x)])==0]
g_old <- gn_1[gn_1>0]

knew <- do.call(rbind,lapply(names(g_new),s2v))
fnew <- predict(x$fit,knew) 

kold <- do.call(rbind,lapply(names(g_old),s2v))
fold <- predict(x$fit,kold) 

nn_old <- gen_all_neighbours(names(g_old))
fnnold <- predict(x$fit,nn_old)
nn_old <- apply(nn_old,1,paste,collapse=".")
nrep <- as.numeric(g_new[nn_old])
nrep[is.na(nrep)] <- 0

fnnold <- cbind(fnnold,nrep)
fnnold <- data.frame(fnnold)
colnames(fnnold) <- c("fitness","nrep")
fnnold$emerged <- fnnold$nrep>0
fnnold$id <- head(unlist(strsplit(fi,split=".Rds")),1)
fnnold
}

dir <- "data/salehi/alfak_fits_minobs_adaptive_exclude_final/"
ff <- list.files(dir)

df <- pbapply::pblapply(ff,new_kary_predictions)
df <- df[!sapply(df,is.null)]
pvals <- do.call(rbind,lapply(df,function(di){
  tst <- t.test(di$fitness[di$emerged],di$fitness[!di$emerged])
  data.frame(pval=tst$p.value,id=di$id[1],
    mean_emerged = tst$estimate[1],
    mean_unemerged = tst$estimate[2])
}))

df <- do.call(rbind,df)

p1 <- ggplot(df,aes(x=emerged,y=fitness))+
  facet_wrap(~id,scales="free",nrow=2)+
  geom_violin()
p1

p2 <- ggplot(pvals,aes(x=mean_emerged,y=mean_unemerged))+
  geom_point()+
  geom_abline()+
  geom_label_repel(aes(label=format(pval, scientific = TRUE,digits=2)))
p2


```

```{r}
library(igraph)



dir <- "data/salehi/alfak_fits_minobs_adaptive/"
ff <- list.files(dir)
x <- readRDS(paste0(dir,ff[1]))
x <- getBest(x)
x <- x$xo
x <- x[x$id=="fq",]

v <- do.call(rbind,lapply(rownames(x),s2v))

d <- as.matrix(dist(v,method = "manhattan"))
d <- d==1

g <- graph_from_adjacency_matrix(d,weighted = T)


mst <- mst(g)
saveWidget(visIgraph(mst), file = "test.html")

```
