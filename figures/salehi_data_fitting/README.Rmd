---
title: "README"
author: "Richard J Beck"
date: "`r Sys.Date()`"
output:
  md_document:
    variant: markdown_github
---

Fitting ALFA-K model to Salehi data

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/projects/008_birthrateLandscape/ALFA-K/")
```

```{r}
library(gtable)
library(ape)
library(ggtree)
library(treeio)
library(ggplot2)
library(xlsx)
source("utils/ALFA-K.R")
source("utils/comparison_functions.R")
lineage_info <- function(ln){
  treat_numeric <- c(n=0,y=1)
  has_descendents <- length(ln$dec1)>0
  has_parents <- sum(is.na(m$parent[m$uid%in%ln$ids]))==0
  treatments <- m$on_treatment[m$uid%in%ln$ids]
  nChanges <- sum(abs(diff(treat_numeric[treatments])))
  treatment_status <- "mixed"
  if(mean(treatments=="n")==1) treatment_status <- "off"
  if(mean(treatments=="y")==1) treatment_status <- "on"
  id <- tail(ln$ids,1)
  cellLine <- m$PDX_id[m$uid==id]
  sid <- paste(gsub(" ","", m$label[id==m$uid],fixed = TRUE),
               m$timepoint[id==m$uid],sep = "_")
  data.frame(id=sid,cellLine,has_descendents,has_parents,nChanges,treatment_status)
  
}
getBest <- function(xi){
  xi <- xi[!sapply(xi,is.null)]
  if(length(xi)==0) return(NULL)
  cor<-sapply(xi, function(xij) xij$vx_cor)
  Rsq<-sapply(xi, function(xij) {
    xij$xv_res <- xij$xv_res[!is.na(xij$xv_res$f_xv),]
    if(nrow(xij$xv_res)<2) return(-Inf)
    R2(xij$xv_res$f_est,xij$xv_res$f_xv)
  })
  n <-sapply(xi, function(xij) nrow(xij$xv_res))
  goodness <- Rsq*n
  j <- which.max(goodness)
  xi[[j]]
  
}
longest_cons <- function(ff,longest=T){
  ids <- sapply(ff, function(fi){
    paste(head(unlist(strsplit(fi,split="_")),2),collapse="_")
  })
  ff <- split(ff,f=ids)
  
  ff <- sapply(ff, function(fi){
    fi <- fi[order(fi)]
    if(longest) return(tail(fi,1))
    return(head(fi,1))
  })
  as.character(ff)
}
```
First source the following to prepare the sample data (the third one takes a few hours)
```{r,eval=F}

source("figures/salehi_data_fitting/extract_cn_profiles.R")
source("figures/salehi_data_fitting/extract_lineage.R") ## v2
source("figures/salehi_data_fitting/fit_alfak.R")
```




NEW: Results of ALFA-K across all possible lineages

NOTE: NaN values in the cross validation represent instances where the neighbour fitness estimation step cannot be correctly performed.

```{r}
source("utils/comparison_functions.R")

lineage_info <- function(ln){
  treat_numeric <- c(n=0,y=1)
  has_descendents <- length(ln$dec1)>0
  has_parents <- sum(is.na(m$parent[m$uid%in%ln$ids]))==0
  treatments <- m$on_treatment[m$uid%in%ln$ids]
  nChanges <- sum(abs(diff(treat_numeric[treatments])))
  treatment_status <- "mixed"
  if(mean(treatments=="n")==1) treatment_status <- "off"
  if(mean(treatments=="y")==1) treatment_status <- "on"
  id <- tail(ln$ids,1)
  sid <- paste(gsub(" ","", m$label[id==m$uid],fixed = TRUE),
               m$timepoint[id==m$uid],sep = "_")
  data.frame(id=sid,has_descendents,has_parents,nChanges,treatment_status)
  
}


get_r2 <- function(id,mo){
  x <- readRDS(paste0(dir,mo,"/",id,"."))
  xvr <- x$xv_res
  maxf <- max(xvr$f_est)
  xvr <- xvr[!is.na(xvr$f_xv),]
  r2 <- R2(obs = xvr$f_xv,pred=xvr$f_est)
  id <- unlist(strsplit(id,split=".Rds"))[1]
  id <- unlist(strsplit(id,split="_"))
  if(length(id)>8){
    idt <- tail(id,7)
    idh <- head(id,length(id)-7)
    idh <- paste(idh,collapse="_")
    id <- c(idh,idt)
  }
  mo <- tail(unlist(strsplit(mo,split="_")),1)
  res <- c(id[c(1,2,4,6,8)],mo,maxf,r2)
  names(res) <- c("datasetname","timepoint","samples","dec1","dec2","min_obs","maxf","r2")
  return(res)
}

m <- read.csv("data/salehi/metadata.csv")
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
linfo <- do.call(rbind,lapply(lineages,lineage_info))
linfo$filenames <- paste0(rownames(linfo),".Rds")
rownames(linfo) <- linfo$filenames
dir <- "data/salehi/alfak_fits/"
min_obs <- list.files(dir)

x <- lapply(min_obs, function(mo){
  ff <- list.files(paste0(dir,mo))
  ff <- ff[ff%in%linfo$filenames]
  res <- data.frame(do.call(rbind,lapply(ff,get_r2,mo=mo)))
  res <- cbind(res,linfo[ff,])
  
})

x <- data.frame(do.call(rbind,x))
rownames(x) <- NULL
x <- x[,!colnames(x)%in%c("datasetname","timepoint")]
x$r2 <- as.numeric(x$r2)
x$maxf <- as.numeric(x$maxf)

x$r2[x$r2<(-1)] <- -1
x <- x[order(x$r2,decreasing=T),]

saveRDS(x,"figures/salehi_data_fitting/fit_summaries.Rds")

p <- ggplot(x,aes(x=r2))+
  facet_grid(rows=vars(stringr::str_pad(min_obs,width = 2)),cols=vars(stringr::str_pad(samples,width = 2)))+
  geom_histogram(binwidth = 0.2)
p
```

```{r}
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
#x <- x[x$declevel==1,]

## untreated samples worked well - perhaps due to longer lineages?
x[!x$has_parents&!x$has_descendents&x$treatment_status=="off"&x$min_obs==5,]

## treated samples worked poorly - perhaps due to shorter lineages?
x[!x$has_descendents&x$treatment_status=="on"&x$min_obs==5,]

##samples amenable to forward prediction tests:
nrow(x[x$has_descendents&x$min_obs==5,])






##"core" samples
xl <- x[!x$has_descendents&x$min_obs==5,]
xl_on <- xl[xl$treatment_status=="on",]
xl_off <- xl[xl$treatment_status!="on",]
xl <- xl[xl$filenames%in%c(longest_cons(xl_off$filenames),longest_cons(xl_on$filenames)),]
xl <- xl[xl$filenames%in%longest_cons(xl$filenames,longest=F),]

## interestingly, I think if you look at the treated lineages you get better R^2 if you bunch treated/untreated passages than if you focus exclusively on treated passages. Apparently having more passages makes up for the change in condition. Perhaps it would be better to use these as our core samples? 
xl <- x[!x$has_descendents&x$min_obs==5,]
xl <- xl[xl$filenames%in%longest_cons(xl$filenames),]

```
Roughness metric as a function of ploidy.

```{r}
source("utils/landscape_functions.R")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
#x <- x[x$filenames%in%longest_cons(x$filenames),]
x <- x[x$r2>0.2,]
ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"
z <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  data.frame(id=fi,mean_f=mean(xi$xo$f_est),sd_f=sd(xi$xo$f_est))
}))
z$treatment_status <- x$treatment_status
z$id <- x$id
p <- ggplot(z,aes(x=id,y=sd_f,fill=treatment_status))+
  geom_col()+
  coord_flip()
p
#stop("comment me out to assess roughness")
y <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  r <- roughness_meas(xi,only_fq=T)
  r$id <- x$id[x$filenames==fi][1]
  return(r)
}))

p <- ggplot(y,aes(x=ploidy))+
  facet_wrap(~id)+
  geom_histogram()
p

pr <- ggplot(y,aes(x=ploidy,y=roughness))+
  facet_wrap(~id,scales="free")+
  geom_point()
pr

p <- ggplot(y,aes(x=ploidy,y=f_est))+
  facet_wrap(~id,scales="free")+
  geom_point()
p

pfr <- ggplot(y,aes(x=roughness,y=f_est))+
  facet_wrap(~id,scales="free")+
  geom_point()
pfr

q <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  r <- nviable_meas(xi,only_fq=T)
  r$id <- x$id[x$filenames==fi][1]
  return(r)
}))

p <- ggplot(q,aes(x=ploidy,y=fviable))+
  facet_wrap(~id,scales="free")+
  geom_point()
p

```
Moran metric as a function of ploidy.

```{r}
source("utils/landscape_functions.R")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
x <- x[x$r2>0.2,]
ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"

#stop("comment me out to assess roughness")
y <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))$xo
  m <- moran_freq(rownames(xi),fitness = xi$f_est)
  m$id <- x$id[x$filenames==fi][1]
  return(m)
}))


pm <- ggplot(y,aes(x=ploidy,y=Ii))+
  facet_wrap(~id,scales="free")+
  geom_point()
pm

```

Is ploidy increasing over time?
```{r}

x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
#x <- x[x$filenames%in%longest_cons(x$filenames),]
x <- x[x$r2>0.2,]

dir <- "data/salehi/alfak_inputs_v2/"
z <- do.call(rbind,pbapply::pblapply(1:nrow(x),function(i){
  fi <- x$filenames[i]
  
  xs <- readRDS(paste0(dir,fi))$x
  vs <- do.call(rbind,lapply(rownames(xs),s2v))
  
  ## sim output population vectors
  csx <- colSums(xs)
  xs <- t(xs)%*%vs
  for(k in 1:nrow(xs)) xs[k,] <- xs[k,]/csx[k]
  xs <- rowMeans(xs)
  tt <- as.numeric(names(xs))
  data.frame(ploidy=as.numeric(xs),time=tt/max(tt),id=x$id[i])
}))

pp <- ggplot(z,aes(x=time,y=ploidy))+
  facet_wrap(~id,scales="free")+
  geom_point()
pp

```

Correlation between fitnesses on different landscapes:

```{r}
source("utils/landscape_functions.R")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
#x <- x[x$filenames%in%longest_cons(x$filenames),]
x <- x[x$r2>0.2,]
ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"
z <- pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  xii <- gen_all_neighbours(rownames(xi$xo))
  fii <- predict(xi$fit,xii)
  names(fii) <- apply(fii,1,paste,collapse=".")
  fi0 <- xi$xo$f_est
  names(fi0) <- rownames(xi$xo)
  c(fi0,fii)
})

combns <- expand.grid(a=1:length(z),b=1:length(z))

combns$cc <- sapply(1:nrow(combns), function(i){
  za <- z[[combns$a[i]]]
  zb <- z[[combns$b[i]]]
  za <- za[names(za)%in%names(zb)]
  if(length(za)==0) return(NaN)
  zb <- zb[names(za)]
  cc <- cor(za,zb)
  return(cc)
})
combns$a <- x$id[combns$a]
combns$b <- x$id[combns$b]

p <- ggplot(combns,aes(x=a,y=b,fill=cc))+
  geom_raster()+
  scale_x_discrete("")+
  scale_y_discrete("")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p

```



Testing forward prediction accuracy:
```{r}
m <- read.csv("data/salehi/metadata.csv")
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
cnmat <- readRDS("data/salehi/chrom_level_cn.Rds")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
xf <- x[x$has_descendents&x$min_obs==5,]
ids <- as.character(sapply(xf$filenames,function(fi){head(unlist(strsplit(fi,split=".Rds")),1)}))
simdir <- "data/salehi/forward_sims_v2/minobs_5/"

tst <- which(ids%in%list.files(simdir))

df <- do.call(rbind,pbapply::pblapply(tst, function(i){
  si <- paste0(simdir,ids[i],"/output/00000/")
  xs <- proc_sim(si,times=seq(0,300,150))$x
  vs <- do.call(rbind,lapply(rownames(xs),s2v))
  li <- lineages[[ids[i]]]
  
  ## sim output population vectors
  csx <- colSums(xs)
  xs <- t(xs)%*%vs
  for(k in 1:nrow(xs)) xs[k,] <- xs[k,]/csx[k]
  target_library_ids <- m$library_ids[m$uid==tail(li$ids,1)]
  target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
  x0 <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
  
  dfi <- do.call(rbind,lapply(1:length(li$dec1), function(j){
    target_library_ids <- m$library_ids[m$uid==li$dec1[j]]
    target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
    xd <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
    
    angles <- apply(xs,1,function(xsi){
      a <- xsi-x0
      b <- xd-x0
      ai <- getangle(a,b)
      
    })
    names(angles) <- paste0("a",names(angles))
    df <- cbind(xf[i,],t(angles))
    df$descendent <- li$dec1[j]
    df$declevel <- 1
    return(df)
  }))
  if(length(li$dec2)>0){
    dfii <- do.call(rbind,lapply(1:length(li$dec2), function(j){
      target_library_ids <- m$library_ids[m$uid==li$dec2[j]]
      target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
      xd <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
      
      angles <- apply(xs,1,function(xsi){
        a <- xsi-x0
        b <- xd-x0
        ai <- getangle(a,b)
        
      })
      names(angles) <- paste0("a",names(angles))
      df <- cbind(xf[i,],t(angles))
      df$descendent <- li$dec1[j]
      df$declevel <- 2
      return(df)
    }))
    dfi <- rbind(dfi,dfii)
  }
  
  return(dfi)
  
}))

saveRDS(df,"figures/salehi_data_fitting/validation_summaries.Rds")

```

```{r}

wrap_res <- function(df){
  angle_data <- df[,paste0("a",seq(0,300,150))]
  df <- df[,!colnames(df)%in%paste0("a",seq(0,300,150))]
  df$angle <- angle_data$a150
  df$angle[df$declevel==2] <- angle_data$a300
  df$pos_r2 <- df$r2>0
  df$good_r2 <- df$r2>0.3
  return(df)
  
}

df <- wrap_res(readRDS("figures/salehi_data_fitting/validation_summaries.Rds"))
p <- ggplot(df,aes(x=samples,y=angle))+
  facet_grid(cols=vars(pos_r2),rows=vars(declevel))+
  geom_violin()
p

```




```{r}
source("utils/comparison_functions.R")
source("utils/visualisation_functions.R")

proc_input <- function(fi){
  id <- head(unlist(strsplit(fi,split=".Rds")),1)
  uid <- tail(l[[id]]$ids,1)
  id2 <- paste(m$label[m$uid==uid],m$timepoint[m$uid==uid],sep="_")
  id2 <- gsub(" ","",id2)
  x <- readRDS(paste0(fit_dir,fi))
  corc <- cor(x$xv$f_est,x$xv$f_xv,use = "complete")
  r2 <- R2(x$xv_res$f_est[!is.na(x$xv_res$f_xv)],x$xv_res$f_xv[!is.na(x$xv_res$f_xv)])
  data.frame(id=id,id2=id2,R2=r2,cor=corc)
}

get_xv_df <- function(fi){
  x <- readRDS(paste0(fit_dir,fi))
  x$xv_res
}

gen_plot <- function(fi,nclones=8){
  x <- readRDS(paste0(fit_dir,fi))
  d <- readRDS(paste0(data_dir,fi))
  x2 <- melt_for_plotting(d,nclones=nclones,x)

  p <- ggplot(x2$data,aes(x=time,y=frequency,color=karyotype))+
    facet_wrap(~karyotype)+
    geom_point(size=2)+
    geom_line(data=x2$fit)+
    theme_classic(base_size=12)
  p
}

m <- read.csv("data/salehi/metadata.csv")
l <- readRDS("figures/salehi_data_fitting/lineages.Rds")
fit_dir <- "data/salehi/alfak_fits/minobs_5/"
data_dir <-  "data/salehi/alfak_inputs_v2/"
ff <- list.files(fit_dir)

df <- do.call(rbind,lapply(ff,proc_input))
gen_plot("SA000_X7_l_4_d1_0_d2_0.Rds")
gen_plot("SA609R1_X6_l_3_d1_0_d2_0.Rds")
gen_plot("SA609R1_X7_l_4_d1_0_d2_0.Rds")

gen_plot("SA1035T_X8_l_4_d1_0_d2_0.Rds")
xv <- get_xv_df("SA1035T_X8_l_4_d1_0_d2_0.Rds")
v <- do.call(rbind,lapply(rownames(xv), s2v))
h <- hclust(dist(v,method = "manhattan"))
h$labels <- round(xv$f_est,digits=3)
plot(h)

gen_plot("SA609U1_X8_l_8_d1_0_d2_0.Rds")
xv <- get_xv_df("SA609U1_X8_l_8_d1_0_d2_0.Rds")
v <- do.call(rbind,lapply(rownames(xv), s2v))
h <- hclust(dist(v,method = "manhattan"))
h$labels <- round(xv$f_est,digits=3)
plot(h)

gen_plot("SA535_CISPLATIN_CombinedT_X9_l_4_d1_0_d2_0.Rds")
get_xv_df("SA535_CISPLATIN_CombinedT_X9_l_4_d1_0_d2_0.Rds")
```

Fit alfa-k and test performance across all lineages. It turned out that for these cell lines the results of the cross validation procedure could be quite sensitive to the value of min_obs. Therefore alfa-k was fit using all possible values for min_obs>5 on each cell line and the "best" value of min_obs was used. The criterion for best was the value that maximised the product of $r^2$ with the number of unique karyotypes considered as frequent clones. This was done instead of simply taking the highest $r^2$ value, to prevent choosing values for min_obs that would result in high $r^2$ values across only a couple of karyotypes.

One thing we will have to explain is why we get such a good result for the Her2+ cell line when Salehi et al didn't. One possibilitiy is that the more detailed resolution CNA info they used to cluster cells was a red herring. 



```{r}

dir <- "data/salehi/alfak_fits_minobs_adaptive/"
ff <- list.files(dir)
x <- do.call(rbind,lapply(ff, function(fi) {
  print(fi)
  xi <- readRDS(paste0(dir,fi))
  xi <- xi[!sapply(xi,is.null)]
  if(length(xi)==0) return(NULL)
  cor<-sapply(xi, function(xij) xij$vx_cor)
  Rsq<-sapply(xi, function(xij) {
      xij$xv_res <- xij$xv_res[!is.na(xij$xv_res$f_xv),]
    if(nrow(xij$xv_res)<2) return(-Inf)
    R2(xij$xv_res$f_est,xij$xv_res$f_xv)
  })
  min_obs <- sapply(xi, function(xij) xij$min_obs)
  n <-sapply(xi, function(xij) nrow(xij$xv_res))
  df <- data.frame(id=unlist(strsplit(fi,split=".Rds"))[1],
                   Rsq=Rsq,n=n,min_obs=min_obs)
  df$Rsq <- pmax(df$Rsq,-1)
  return(df)
}))

p <- ggplot(x,aes(x=n,y=Rsq))+
  facet_wrap(~id)+
  geom_point()
p

p <- ggplot(x,aes(x=min_obs,y=Rsq))+
  facet_wrap(~id)+
  geom_point()+
  scale_x_log10()
p

```

```{r}


dir <- "data/salehi/alfak_fits_minobs_adaptive_exclude_final/"
ff <- list.files(dir)

x <- do.call(rbind,lapply(ff, function(fi) {
  print(fi)
xi <- readRDS(paste0(dir,fi))
xi <- xi[!sapply(xi,is.null)]
if(length(xi)==0) return(NULL)
cor<-sapply(xi, function(xij) xij$vx_cor)
Rsq<-sapply(xi, function(xij) {
  xij$xv_res <- xij$xv_res[!is.na(xij$xv_res$f_xv),]
  if(nrow(xij$xv_res)<2) return(-Inf)
  R2(xij$xv_res$f_est,xij$xv_res$f_xv)
})
n <-sapply(xi, function(xij) nrow(xij$xv_res))

goodness <- Rsq*n

j <- which.max(goodness)

df <- data.frame(cor=cor[j],
                 R2 = Rsq[j],
                 n=n[j],
                 id=unlist(strsplit(fi,split=".Rds"))[1])
}))

x$R2 <- pmax(-1,x$R2)

p0 <- ggplot(x,aes(x=id,y=R2))+
  geom_col()+
  coord_flip()+
  scale_x_discrete("")+
  scale_y_continuous(expression(R^2))
p0

p1 <- ggplot(x,aes(x=id,y=cor))+
  geom_col()+
  coord_flip()+
  scale_x_discrete("")+
  scale_y_continuous("spearman correlation")
p1

p2 <- ggplot(x,aes(x=id,y=n))+
  geom_col()+
  coord_flip()+
  scale_x_discrete("")+
  scale_y_continuous("number of frequent karyotypes")
p2



```

It would be very interesting to compare how similar population evolution was in the instances where we have parallel evolution going on. 

The result is not as expected

```{r}
source("utils/comparison_functions.R")
x <- readRDS("data/salehi/chrom_level_cn.Rds")
m <- read.csv("data/salehi/metadata.csv")
m <- m[m$PDX_id=="SA609",]

nm <- table(m$parent)
nm <- names(nm)[nm>1]

l <- do.call(rbind,lapply(nm, function(ni) {
  children <- m$uid[m$parent==ni & !is.na(m$parent)]
  combos <- combn(1:length(children),2)
  cond_match <- apply(combos,2,function(ci){
    m$on_treatment[m$uid==children[ci[1]]]==m$on_treatment[m$uid==children[ci[2]]]
  })
  data.frame(parent=ni,child1=children[combos[1,]],
             child2=children[combos[2,]],cond_match)
}))

l <- cbind(l,data.frame(t(apply(l[,1:3],1,function(li){
  sapply(li, function(lij) m$library_ids[m$uid==lij])
}))))
colnames(l)[1:3] <- paste0("uid_",colnames(l)[1:3])



l$angles <- sapply(1:nrow(l), function(i){
  idpar <- unlist(strsplit(l$parent[i],split=";"))
  idc1 <- unlist(strsplit(l$child1[i],split=";"))
  idc2 <- unlist(strsplit(l$child2[i],split=";"))
  
  vpar <- colMeans(do.call(rbind,lapply(idpar,function(id) x[[id]])))
  vc1 <- colMeans(do.call(rbind,lapply(idc1,function(id) x[[id]])))-vpar
  vc2 <- colMeans(do.call(rbind,lapply(idc2,function(id) x[[id]])))-vpar
  
  getangle(vc1,vc2)
})


p <- ggplot(l,aes(x=angles))+
  facet_wrap(~cond_match)+
  geom_histogram(binwidth=10)
p

aggregate(l$angles,by=list(l$cond_match),mean)
```
```{r}
source("utils/comparison_functions.R")
x <- readRDS("data/salehi/chrom_level_cn.Rds")
m <- read.csv("data/salehi/metadata.csv")
#m <- m[m$PDX_id=="SA609",]

nm <- table(m$parent)
nm <- names(nm)[nm>1]

l <- do.call(rbind,lapply(nm, function(ni) {
  children <- m$uid[m$parent==ni & !is.na(m$parent)]
  combos <- combn(1:length(children),2)
  cond_match <- apply(combos,2,function(ci){
    m$on_treatment[m$uid==children[ci[1]]]==m$on_treatment[m$uid==children[ci[2]]]
  })
  data.frame(parent=ni,child1=children[combos[1,]],
             child2=children[combos[2,]],cond_match)
}))

l <- cbind(l,data.frame(t(apply(l[,1:3],1,function(li){
  sapply(li, function(lij) m$library_ids[m$uid==lij])
}))))
colnames(l)[1:3] <- paste0("uid_",colnames(l)[1:3])



l$w <- sapply(1:nrow(l), function(i){
  idpar <- unlist(strsplit(l$parent[i],split=";"))
  idc1 <- unlist(strsplit(l$child1[i],split=";"))
  idc2 <- unlist(strsplit(l$child2[i],split=";"))
  
  x0 <- do.call(rbind,lapply(idpar,function(id) x[[id]]))
  x1 <- do.call(rbind,lapply(idc1,function(id) x[[id]]))
  x2 <- do.call(rbind,lapply(idc2,function(id) x[[id]]))
  
  x0 <- transport::wpp(x0,mass=rep(1/nrow(x0),nrow(x0)))
  x1 <- transport::wpp(x1,mass=rep(1/nrow(x1),nrow(x1)))
  x2 <- transport::wpp(x2,mass=rep(1/nrow(x2),nrow(x2))) 
  
  d01 <- transport::wasserstein(x0,x1)
  d02 <- transport::wasserstein(x0,x2)
  d12 <- transport::wasserstein(x1,x2)
  d12/(d01+d02)
})


p <- ggplot(l,aes(x=w))+
  facet_wrap(~cond_match)+
  geom_histogram()
p

aggregate(l$w,by=list(l$cond_match),mean)
```

```{r}

f0 <- list.files("data/salehi/forward_sims/")

df <- do.call(rbind,lapply(f0,function(fi){
x <- readRDS(paste0("data/salehi/alfak_inputs/",fi,".Rds"))$x
k <- do.call(rbind,lapply(rownames(x),s2v))

x0 <- colSums(x[,ncol(x)-1]*k)/sum(x[,ncol(x)-1])
x1 <- colSums(x[,ncol(x)]*k)/sum(x[,ncol(x)])-x0

dir <- paste0("data/salehi/forward_sims/",fi,"/output/00000/")
ff <- list.files(dir)
ff <- ff[!ff%in%c("log.txt","summary.txt")]
tt <- as.numeric(sapply(ff, function(fi) unlist(strsplit(fi,split=".csv"))[1]))
xtst <- proc_sim(dir,times=tt)$x

k <- do.call(rbind,lapply(rownames(xtst),s2v))

angles <- sapply(1:ncol(xtst), function(i){
  xni <- colSums(xtst[,i]*k)/sum(xtst[,i])-x0
  getangle(xni,x1)
})
tt <- colnames(xtst)  
data.frame(id=fi,angles,time=as.numeric(tt))
}))

p <- ggplot(df,aes(x=time,y=angles))+
  facet_wrap(~id)+
  geom_point()
p



```

Below is stuff for plotting the lineages

NEW (more lineages)
```{r}
## some lineages have a parent and a child per passage. Must be careful to collapse these. 
m <- read.csv("data/salehi/metadata.csv")

lineage_wrapper <- function(ids){
  list(ids=ids)
}

lineage_generator <- function(uid){
  ids <- c()
  lineages <- list()
  while(!is.na(uid)){
    ids <- c(uid,ids)
    uid <- m$parent[m$uid==uid]
    if(length(ids)>1) lineages <- c(lineages,lineage_wrapper(ids))
  }
  return(lineages)
}

descendent_checker <- function(ids){
  dec1 <- m$uid[m$parent==tail(ids,1)&!is.na(m$parent)]
  dec2 <- m$uid[m$parent%in%dec1]
  list(ids=ids,dec1=dec1,dec2=dec2)
}

lineage_namer <- function(lineage){
  suffix <- paste0("_l_",length(lineage$ids),"_d1_",length(lineage$dec1),
                   "_d2_",length(lineage$dec2))
  id <- tail(lineage$ids,1)
  sid <- paste(gsub(" ", "", m$datasetname[id==m$uid],fixed = TRUE),m$timepoint[id==m$uid],sep = "_")
  sid <- gsub("/", "", sid,fixed = TRUE)
  paste0(sid,suffix)
}

lineages <- do.call(c,lapply(m$uid,lineage_generator))
lineages <- lapply(lineages, descendent_checker)

lnames <- sapply(lineages,lineage_namer)
names(lineages) <- lnames
saveRDS(lineages,"figures/salehi_data_fitting/lineages.Rds")

```
OLD
```{r}

plotmaker <- function(pdx,m){
  print(pdx)
  conds <- data.frame(id=c("A96146A","A96149B","A118833A","A110673B","A118862A",
                         "A96219B","A118845B","A98244A","A98256A","A98283A",
                         "A96162B"),
                    dt=c(5,5,15,15,15,15,15,15,15,15,15),
                    mintp=c(1,1,1,3,3,1,1,5,1,4,1))

z <- lapply(1:nrow(conds),function(i){
  mintp <- paste0("X",conds$mintp[i])
  id <- conds$id[i]
  sid <- paste(gsub(" ", "", m$label[grepl(id,m$library_ids)],fixed = TRUE),m$timepoint[grepl(id,m$library_ids)],sep = "_")
  sid <- gsub("/", "", sid,fixed = TRUE)
  
  uids <- c(m$uid[grepl(id,m$library_ids)],m$parent[grepl(id,m$library_ids)])
  
  while(!is.na(tail(uids,1))){
    uids <- c(uids,m$parent[m$uid==tail(uids,1)])
  }
  
  msel <- m[m$uid%in%uids,]

  if(msel$PDX_id[1]!=pdx) return(NULL)
    msel[msel$timepoint>=mintp,]
})

z <- z[!sapply(z,is.null)]

maxl <- max(sapply(z,nrow))

uids <- do.call(rbind,z)
uids <- unique(uids$uid)

d <- matrix(0,nrow=length(uids),ncol=length(z))
for(i in 1:length(z)){
  d[uids%in%z[[i]]$uid,i] <- 1 
}
for(i in 1:nrow(d)) d[i,] <- d[i,]/sum(d[i,])
d <- data.frame(d)



m <- read.csv("data/salehi/metadata.csv")
m <- m[m$PDX_id==pdx,]
m$on_treatment <- c(n="no",y="yes")[m$on_treatment]
m2 <- m[!is.na(m$parent),]

tr <- as.phylo(m2[,c("uid","parent")])
tr$edge.length <- rep(1,nrow(tr$edge))

x <- as_tibble(tr)
nodelablr <- x$node
names(nodelablr) <- x$label
x$on_treatment <- sapply(x$label,function(i){
  m$on_treatment[m$uid==i]
})
tr <- as.treedata(x)

ff <- cbind(node=nodelablr[as.character(uids)],d)
tmp <- reshape2::melt(ff,id.vars="node")

pies <- nodepie(ff,cols=2:(1+length(z)))
pies <- lapply(pies, function(g) g+scale_fill_viridis_d())

##create  a dummy data frame to generate a fillable legend

nodesz <- .32#0.2*maxl/8
if(pdx=="SA609") nodesz <- 0.25
if(pdx=="SA906") nodez <- 0.4
df2 <- data.frame(x=rep(Inf,length(z)),
                  y=rep(Inf,length(z)),
                  z=paste0("X",1:length(z)))

p <- ggtree(tr)+ 
  geom_point(data=df2,aes(x=x,y=y,fill=z,linetype=NULL),shape=21)+
    aes(linetype=on_treatment)+
    #geom_nodepoint()+
  geom_inset(pies, width = nodesz, height = nodesz, x = "node")+
  ggtitle(pdx)+
  scale_linetype_discrete("on treament")+
  scale_fill_viridis_d("lineage")
p
}

```
```{r}
m <- read.csv("data/salehi/metadata.csv")
pdx <- c("SA906","SA609","SA1035","SA535")#,"SA532")
x <- lapply(pdx,plotmaker,m=m)
#x
#p <- cowplot::plot_grid(x[[1]],x[[2]],x[[3]],x[[4]],ncol=2)
```
http://127.0.0.1:32487/graphics/plot_zoom_png?width=632&height=314


Can we predict emergent karyotypes?
```{r}
library(ggrepel)
new_kary_predictions <- function(fi){
  
x <- readRDS(paste0(dir,fi))
x <- getBest(x)
if(is.null(x)) return(NULL)
ddir <- "data/salehi/alfak_inputs/"
d <- readRDS(paste0(ddir,fi))

gn_1 <- d$x[,ncol(d$x)-1]
gn <- d$x[,ncol(d$x)]

g_new <- gn[gn>0 & rowSums(d$x[,-ncol(d$x)])==0]
g_old <- gn_1[gn_1>0]

knew <- do.call(rbind,lapply(names(g_new),s2v))
fnew <- predict(x$fit,knew) 

kold <- do.call(rbind,lapply(names(g_old),s2v))
fold <- predict(x$fit,kold) 

nn_old <- gen_all_neighbours(names(g_old))
fnnold <- predict(x$fit,nn_old)
nn_old <- apply(nn_old,1,paste,collapse=".")
nrep <- as.numeric(g_new[nn_old])
nrep[is.na(nrep)] <- 0

fnnold <- cbind(fnnold,nrep)
fnnold <- data.frame(fnnold)
colnames(fnnold) <- c("fitness","nrep")
fnnold$emerged <- fnnold$nrep>0
fnnold$id <- head(unlist(strsplit(fi,split=".Rds")),1)
fnnold
}

dir <- "data/salehi/alfak_fits_minobs_adaptive_exclude_final/"
ff <- list.files(dir)

df <- pbapply::pblapply(ff,new_kary_predictions)
df <- df[!sapply(df,is.null)]
pvals <- do.call(rbind,lapply(df,function(di){
  tst <- t.test(di$fitness[di$emerged],di$fitness[!di$emerged])
  data.frame(pval=tst$p.value,id=di$id[1],
    mean_emerged = tst$estimate[1],
    mean_unemerged = tst$estimate[2])
}))

df <- do.call(rbind,df)

p1 <- ggplot(df,aes(x=emerged,y=fitness))+
  facet_wrap(~id,scales="free",nrow=2)+
  geom_violin()
p1

p2 <- ggplot(pvals,aes(x=mean_emerged,y=mean_unemerged))+
  geom_point()+
  geom_abline()+
  geom_label_repel(aes(label=format(pval, scientific = TRUE,digits=2)))
p2


```

```{r}
library(igraph)



dir <- "data/salehi/alfak_fits_minobs_adaptive/"
ff <- list.files(dir)
x <- readRDS(paste0(dir,ff[1]))
x <- getBest(x)
x <- x$xo
x <- x[x$id=="fq",]

v <- do.call(rbind,lapply(rownames(x),s2v))

d <- as.matrix(dist(v,method = "manhattan"))
d <- d==1

g <- graph_from_adjacency_matrix(d,weighted = T)


mst <- mst(g)
saveWidget(visIgraph(mst), file = "test.html")

```
