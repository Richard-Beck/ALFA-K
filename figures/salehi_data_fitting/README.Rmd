---
title: "README"
author: "Richard J Beck"
date: "`r Sys.Date()`"
output:
  md_document:
    variant: markdown_github
---

Fitting ALFA-K model to Salehi data

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/projects/008_birthrateLandscape/ALFA-K/")
```

First we will pull all the lineages from the metadata. A lineage is defined as any sequence of two or more consecutive samples. 
```{r}

m <- read.csv("data/salehi/metadata.csv")

lineage_wrapper <- function(ids){
  list(ids=ids)
}

lineage_generator <- function(uid){
  ids <- c()
  lineages <- list()
  while(!is.na(uid)){
    ids <- c(uid,ids)
    uid <- m$parent[m$uid==uid]
    if(length(ids)>1) lineages <- c(lineages,lineage_wrapper(ids))
  }
  return(lineages)
}

descendent_checker <- function(ids){
  dec1 <- m$uid[m$parent==tail(ids,1)&!is.na(m$parent)]
  dec2 <- m$uid[m$parent%in%dec1]
  list(ids=ids,dec1=dec1,dec2=dec2)
}

lineage_namer <- function(lineage){
  suffix <- paste0("_l_",length(lineage$ids),"_d1_",length(lineage$dec1),
                   "_d2_",length(lineage$dec2))
  id <- tail(lineage$ids,1)
  sid <- paste(gsub(" ", "", m$datasetname[id==m$uid],fixed = TRUE),m$timepoint[id==m$uid],sep = "_")
  sid <- gsub("/", "", sid,fixed = TRUE)
  paste0(sid,suffix)
}

lineages <- do.call(c,lapply(m$uid,lineage_generator))
lineages <- lapply(lineages, descendent_checker)

lnames <- sapply(lineages,lineage_namer)
names(lineages) <- lnames
saveRDS(lineages,"figures/salehi_data_fitting/lineages.Rds")

```

Run the following scripts (in order) to preprocess & fit the Salehi data.The third script will take several hours on a regular PC. 
```{r,eval=F}
source("figures/salehi_data_fitting/extract_cn_profiles.R")
source("figures/salehi_data_fitting/extract_lineage_v2.R") 
source("figures/salehi_data_fitting/fit_alfak_v2.R")
```

```{r,message=F,warning=F}
library(gtable)
library(ape)
library(ggtree)
library(treeio)
library(ggplot2)
library(xlsx)
source("utils/ALFA-K.R")
source("utils/comparison_functions.R")
signr <- function(pval){
  if(pval<0.001) return("***")
  if(pval<0.01) return("**")
  if(pval<0.05) return("*")
  return("")
}
lineage_info <- function(ln){
  treat_numeric <- c(n=0,y=1)
  has_descendents <- length(ln$dec1)>0
  has_parents <- sum(is.na(m$parent[m$uid%in%ln$ids]))==0
  treatments <- m$on_treatment[m$uid%in%ln$ids]
  nChanges <- sum(abs(diff(treat_numeric[treatments])))
  treatment_status <- "mixed"
  if(mean(treatments=="n")==1) treatment_status <- "off"
  if(mean(treatments=="y")==1) treatment_status <- "on"
  id <- tail(ln$ids,1)
  cellLine <- m$PDX_id[m$uid==id]
  sid <- paste(gsub(" ","", m$label[id==m$uid],fixed = TRUE),
               m$timepoint[id==m$uid],sep = "_")
  data.frame(id=sid,uid=id,cellLine,has_descendents,has_parents,nChanges,treatment_status)
  
}

longest_cons <- function(ff,longest=T){
  ids <- sapply(ff, function(fi){
    fsplit <- unlist(strsplit(fi,split="_"))
    lsplit <- length(fsplit)
    fsplit <- fsplit[1:(lsplit-6)]
    paste(fsplit,collapse="_")
  })
  ff <- split(ff,f=ids)
  
  ff <- sapply(ff, function(fi){
    fi <- fi[order(fi)]
    if(longest) return(tail(fi,1))
    return(head(fi,1))
  })
  as.character(ff)
}
```


Results of ALFA-K across all possible lineages

NOTE: NaN values in the cross validation represent instances where the neighbour fitness estimation step cannot be correctly performed (due to not enough karyotypes in the input).

```{r}
source("utils/comparison_functions.R")

lineage_info <- function(ln){
  treat_numeric <- c(n=0,y=1)
  has_descendents <- length(ln$dec1)>0
  has_parents <- sum(is.na(m$parent[m$uid%in%ln$ids]))==0
  treatments <- (m$on_treatment[m$uid%in%ln$ids])[-1]
  nChanges <- sum(abs(diff(treat_numeric[treatments])))
  treatment_status <- "mixed"
  if(mean(treatments=="n")==1) treatment_status <- "off"
  if(mean(treatments=="y")==1) treatment_status <- "on"
  id <- tail(ln$ids,1)
  sid <- paste(gsub(" ","", m$label[id==m$uid],fixed = TRUE),
               m$timepoint[id==m$uid],sep = "_")
  data.frame(id=sid,uid=id,has_descendents,has_parents,nChanges,treatment_status)
  
}


get_r2 <- function(id,mo){
  x <- readRDS(paste0(dir,mo,"/",id,"."))
  xvr <- x$xv_res
  maxf <- max(xvr$f_est)
  xvr <- xvr[!is.na(xvr$f_xv),]
  r2 <- R2(obs = xvr$f_xv,pred=xvr$f_est)
  id <- unlist(strsplit(id,split=".Rds"))[1]
  id <- unlist(strsplit(id,split="_"))
  if(length(id)>8){
    idt <- tail(id,7)
    idh <- head(id,length(id)-7)
    idh <- paste(idh,collapse="_")
    id <- c(idh,idt)
  }
  mo <- tail(unlist(strsplit(mo,split="_")),1)
  res <- c(id[c(1,2,4,6,8)],mo,maxf,r2)
  names(res) <- c("datasetname","timepoint","samples","dec1","dec2","min_obs","maxf","r2")
  return(res)
}

m <- read.csv("data/salehi/metadata.csv")
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
linfo <- do.call(rbind,lapply(lineages,lineage_info))
linfo$filenames <- paste0(rownames(linfo),".Rds")
rownames(linfo) <- linfo$filenames
dir <- "data/salehi/alfak_fits/"
min_obs <- list.files(dir)

x <- pbapply::pblapply(min_obs, function(mo){
  ff <- list.files(paste0(dir,mo))
  ff <- ff[ff%in%linfo$filenames]
  res <- data.frame(do.call(rbind,lapply(ff,get_r2,mo=mo)))
  res <- cbind(res,linfo[ff,])
  
})

x <- data.frame(do.call(rbind,x))
rownames(x) <- NULL
x <- x[,!colnames(x)%in%c("datasetname","timepoint")]
x$r2 <- as.numeric(x$r2)
x$maxf <- as.numeric(x$maxf)

x$r2[x$r2<(-1)] <- -1
x <- x[order(x$r2,decreasing=T),]

saveRDS(x,"figures/salehi_data_fitting/fit_summaries.Rds")

```


```{r}

label_proc <- function(id){
  id <- unlist(strsplit(id,split="_"))
  label<-id[1]
  label <- m$label[gsub(" ","",m$label)==label]
  label <- unlist(strsplit(label,split=" "))
  pdx <- label[1]
  details <- label[2]
  paste(pdx,details,collapse="")
}

get_pdx_id <- function(id){
  pdx_ids <- c("SA609","HER2+","p53-/-a","p53-/-b","SA535","SA1035")
  names(unlist(sapply(pdx_ids,grep,id)))
}



m <- read.csv("data/salehi/metadata.csv")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[x$min_obs==5,]
x$pdx_id <- as.character(sapply(x$id,get_pdx_id))
p <- ggplot(x,aes(x=stringr::str_pad(samples,width = 2),y=r2))+
  #facet_grid(rows=vars(stringr::str_pad(min_obs,width = 2)))+
  geom_violin()+
  coord_flip()+
  scale_y_continuous(expression(cross~val.~R^2))+
  scale_x_discrete("samples in fit")
p
ggsave("figures/salehi_data_fitting/figures/xval_scores.png",width=3,height=3,units="in")

p <- ggplot(x,aes(x=stringr::str_pad(samples,width = 2),y=r2))+
  facet_wrap(~pdx_id)+
  geom_violin()+
  geom_jitter(height=0,width=0.1)+
  coord_flip()+
  scale_y_continuous(expression(cross~val.~R^2))+
  scale_x_discrete("samples in fit")
p
ggsave("figures/salehi_data_fitting/figures/xval_scores_by_pdx.png",width=4.5,height=3.5,units="in")
```

```{r}
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")

#x <- x[x$declevel==1,]

## untreated samples worked well - perhaps due to longer lineages?
x[!x$has_parents&!x$has_descendents&x$treatment_status=="off"&x$min_obs==5,]

## treated samples worked poorly - perhaps due to shorter lineages?
x[!x$has_descendents&x$treatment_status=="on"&x$min_obs==5,]

##samples amenable to forward prediction tests:
nrow(x[x$has_descendents&x$min_obs==5,])






##"core" samples
xl <- x[!x$has_descendents&x$min_obs==5,]
xl_on <- xl[xl$treatment_status=="on",]
xl_off <- xl[xl$treatment_status!="on",]
xl <- xl[xl$filenames%in%c(longest_cons(xl_off$filenames),longest_cons(xl_on$filenames)),]
xl <- xl[xl$filenames%in%longest_cons(xl$filenames,longest=F),]

## interestingly, I think if you look at the treated lineages you get better R^2 if you bunch treated/untreated passages than if you focus exclusively on treated passages. Apparently having more passages makes up for the change in condition. Perhaps it would be better to use these as our core samples? 
xl <- x[!x$has_descendents&x$min_obs==5,]
xl <- xl[xl$filenames%in%longest_cons(xl$filenames),]

```
Roughness metric as a function of ploidy.



```{r}
source("utils/landscape_functions.R")
meta <- readRDS("data/salehi/metadata.Rds")
x <- readRDS("figures/salehi_data_fitting/fit_summaries_post_jump.Rds")
x <- x[x$r2>0.2&x$min_obs==5,]
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]

#x <- x[x$filenames%in%longest_cons(x$filenames),]

ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"
z <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  data.frame(id=fi,mean_f=mean(xi$xo$f_est),sd_f=sd(xi$xo$f_est))
}))
z$treatment_status <- x$treatment_status
z$id <- x$id
p <- ggplot(z,aes(x=id,y=sd_f,fill=treatment_status))+
  geom_col()+
  coord_flip()
p
#stop("comment me out to assess roughness")
y <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  r <- roughness_meas(xi,only_fq=T)
  uid <- x$uid[x$filenames==fi][1]
  r$id <- paste(meta$PDX_id,meta$linlab)[meta$uid==uid]
  r$uid <- uid
  return(r)
}))

ys <- split(y,f=y$id)
dfcor <- do.call(rbind,lapply(ys, function(yi){
  res <- cor.test(yi$ploidy,yi$roughness,method = "pearson")
  delta_ploidy <- max(yi$ploidy)-min(yi$ploidy)
  data.frame(pval=res$p.value,pearson = res$estimate,delta_ploidy,
             uid=yi$uid[1])
}))
dfcor$id <- rownames(dfcor)
dfcor$sig <- sapply(dfcor$pval,signr)
dfcor$id <- factor(dfcor$id,levels=dfcor$id[order(dfcor$delta_ploidy)])
dfcor$r2 <- sapply(dfcor$uid,function(i){
  x$r2[x$uid==i]
})
p <- ggplot(dfcor,aes(x=id,y=pearson,fill=sig))+
  geom_col()+
  coord_flip()+
  scale_fill_viridis_d("significance")+
  scale_x_discrete("")+
  scale_y_continuous("pearson correlation coefficient")
p
ggsave("figures/salehi_data_fitting/figures/ploidysort_rougness_metric_correlation.png",width=6,height=5,units="in")

dfcor$id <- factor(dfcor$id,levels=dfcor$id[order(dfcor$r2)])
p <- ggplot(dfcor,aes(x=id,y=pearson,fill=sig))+
  geom_col()+
  coord_flip()+
  scale_fill_viridis_d("significance")+
  scale_x_discrete("")+
  scale_y_continuous("pearson correlation coefficient")
p
ggsave("figures/salehi_data_fitting/figures/r2sort_rougness_metric_correlation.png",width=6,height=5,units="in")


```
Moran metric as a function of ploidy.

```{r}
source("utils/landscape_functions.R")
meta <- readRDS("data/salehi/metadata.Rds")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
x <- x[x$r2>0.2,]
ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"

y <- do.call(rbind,pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))$xo
  m <- moran_freq(rownames(xi[xi$id=="fq",]),fitness = xi$f_est[xi$id=="fq"])
  uid <- x$uid[x$filenames==fi][1]
  m$id <- paste(meta$PDX_id,meta$linlab)[meta$uid==uid]
  m$uid <- uid
  return(m)
}))


ys <- split(y,f=y$id)
dfcor <- do.call(rbind,lapply(ys, function(yi){
  res <- cor.test(yi$ploidy,yi$Ii,method = "pearson")
  delta_ploidy <- max(yi$ploidy)-min(yi$ploidy)
  data.frame(pval=res$p.value,pearson = res$estimate,delta_ploidy,
             uid=yi$uid[1])
}))
dfcor$id <- rownames(dfcor)
dfcor$sig <- sapply(dfcor$pval,signr)
dfcor$id <- factor(dfcor$id,levels=dfcor$id[order(dfcor$delta_ploidy)])
dfcor$r2 <- sapply(dfcor$uid,function(i){
  x$r2[x$uid==i]
})
p <- ggplot(dfcor,aes(x=id,y=pearson,fill=sig))+
  geom_col()+
  coord_flip()+
  scale_fill_viridis_d("significance")+
  scale_x_discrete("")+
  scale_y_continuous("pearson correlation coefficient")
p
ggsave("figures/salehi_data_fitting/figures/ploidysort_moran_metric_correlation.png",width=6,height=5,units="in")


dfcor$r2 <- sapply(dfcor$uid,function(i){
  x$r2[x$uid==i]
})
dfcor$id <- factor(dfcor$id,levels=dfcor$id[order(dfcor$r2)])
p <- ggplot(dfcor,aes(x=id,y=pearson,fill=sig))+
  geom_col()+
  coord_flip()+
  scale_fill_viridis_d("significance")+
  scale_x_discrete("")+
  scale_y_continuous("pearson correlation coefficient")
p
ggsave("figures/salehi_data_fitting/figures/r2sort_moran_metric_correlation.png",width=6,height=5,units="in")

y <- do.call(rbind,lapply(ys,function(yi){
  yi$delta_ploidy <- max(yi$ploidy)-min(yi$ploidy)
  yi
}))
y$id <- factor(y$id,levels=unique(y$id[order(y$delta_ploidy)]))
p <- ggplot(y,aes(x=id,y=ploidy))+
  geom_violin()+
  coord_flip()+
    scale_x_discrete("")+
  scale_y_continuous("ploidy")
p
ggsave("figures/salehi_data_fitting/figures/ploidysort_ploidy_dist.png",width=4,height=5,units="in")

y$r2 <- sapply(y$uid,function(i){
  x$r2[x$uid==i]
})
y$id <- factor(y$id,levels=unique(y$id[order(y$r2)]))
p <- ggplot(y,aes(x=id,y=ploidy))+
  geom_violin()+
  coord_flip()+
    scale_x_discrete("")+
  scale_y_continuous("ploidy")
p
ggsave("figures/salehi_data_fitting/figures/r2sort_ploidy_dist.png",width=4,height=5,units="in")

```

```{r}

check_npaths <- function(ff){
  uid <- x$uid[x$filenames==ff][1]
  id <- paste(meta$PDX_id,meta$linlab)[meta$uid==uid]
  x <- readRDS(paste0("data/salehi/alfak_fits/minobs_5/",ff))
  
  xo <- x$xo[x$xo$id=="fq",]
  
  y <- do.call(rbind,lapply(rownames(xo),function(ri){
    nn <- gen_all_neighbours(ri)
    f <- c(predict(x$fit,nn))
    f0 <- xo[ri,"f_est"]
    ploidy <- mean(s2v(ri))
    npaths <- sum(f0<f)
    data.frame(f0,ploidy,npaths)
  }))
  y$id <- id
  y$uid <- uid
  return(y)
}
meta <- readRDS("data/salehi/metadata.Rds")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
x <- x[x$r2>0.2,]
#x <- x[grepl("SA609",x$id),]
ff <- x$filenames

y <- do.call(rbind,lapply(ff,check_npaths))
y <- split(y,f=y$id)
cdf <- do.call(rbind,lapply(y,function(yi){
  cc <- cor.test(yi$ploidy,yi$npaths)
  delta_ploidy <- max(yi$ploidy)-min(yi$ploidy)
  data.frame(pval=cc$p.value,cor=cc$estimate,id=yi$id[1],delta_ploidy,
             uid=yi$uid[1])
}))



cdf$sig <- sapply(cdf$pval,signr)
cdf$id <- factor(cdf$id,levels=unique(cdf$id[order(cdf$delta_ploidy)]))
p <- ggplot(cdf,aes(x=id,y=cor,fill=sig))+
  geom_col()+
  scale_fill_viridis_d("significance")+
  coord_flip()+
  scale_x_discrete("")+
  scale_y_continuous("pearson correlation coefficient")
p

ggsave("figures/salehi_data_fitting/figures/ploidysort_npaths_correlation.png",width=6,height=5,units="in")
cdf$r2 <- sapply(cdf$uid,function(i){
  x$r2[x$uid==i]
})
cdf$id <- factor(cdf$id,levels=cdf$id[order(cdf$r2)])
p <- ggplot(cdf,aes(x=id,y=cor,fill=sig))+
  geom_col()+
  scale_fill_viridis_d("significance")+
  coord_flip()+
  scale_x_discrete("")+
  scale_y_continuous("pearson correlation coefficient")
p
ggsave("figures/salehi_data_fitting/figures/r2sort_npaths_correlation.png",width=6,height=5,units="in")
```

Correlation between fitnesses on different landscapes:

First make a UMAP to show distance between all fitted landscapes:

```{r}
library(umap)

make_umap <- function(x){
  ff <- x$filenames

z <- pbapply::pblapply(ff,function(fi){
 readRDS(paste0(dir,fi))$xo
})

k <- do.call(rbind,lapply(z,function(zi) do.call(rbind,lapply(rownames(zi)[zi$id=="fq"],s2v))))
k <- unique(k)
k.umap = umap(k)
return(k.umap)

}

proj_umap <- function(x,u){
  ff <- x$filenames

  z <- pbapply::pblapply(ff,function(fi){
    readRDS(paste0(dir,fi))$xo
  })
  k.df <- data.frame(u$layout)

  y <- do.call(rbind,lapply(z, function(zi) do.call(rbind,lapply(rownames(zi),s2v)) ))

  df <- predict(k.umap, y) ## 30 secs
  df <- data.frame(df)
  ids <- unlist(lapply(1:length(z), function(i){
    rep(x$uid[i],nrow(z[[i]]))
  }))
  df$uid <- ids
  return(df)
}

m <- read.csv("data/salehi/metadata.csv")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]
x <- x[x$r2>0.2,]
x <- x[x$filenames%in%longest_cons(x$filenames),]

u <- make_umap(x)
saveRDS(u,"figures/salehi_data_fitting/umap.Rds")
df <- proj_umap(x,u)
saveRDS(df,"figures/salehi_data_fitting/umap_df.Rds")

x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
ff <- c( "SA609_X10_l_8_d1_0_d2_0.Rds",
"SA609UnBU_X7_l_6_d1_0_d2_0.Rds",
"SA609R2_X7_l_4_d1_0_d2_0.Rds",
"SA000_X7_l_3_d1_0_d2_0.Rds",
"SA535_CISPLATIN_CombinedT_X10_l_4_d1_0_d2_0.Rds",
"SA535_CISPLATIN_CombinedU_X9_l_5_d1_0_d2_0.Rds")
x <- x[x$filenames%in%ff,]
df <- proj_umap(x,u)
saveRDS(df,"figures/salehi_data_fitting/umap_sel_df.Rds")

```

```{r}
df <- readRDS("figures/salehi_data_fitting/umap_df.Rds")
m <- readRDS("data/salehi/metadata.Rds")

df$pdx_id <- sapply(df$uid, function(i) {
  m$PDX_id[m$uid==i]
  })

df <- df[sample(1:nrow(df)),]

p <- ggplot(df,aes(x=X1,y=X2,color=pdx_id))+
  geom_point()+
  coord_equal()+
  scale_x_continuous("UMAP1")+
  scale_y_continuous("UMAP2")+
  theme_classic()+
  scale_color_discrete("")
p

ggsave("figures/salehi_data_fitting/figures/umap_core.png",width=4,height=4,units="in")


df <- readRDS("figures/salehi_data_fitting/umap_sel_df.Rds")

df$linlab <- sapply(df$uid, function(i) {
  paste(m$PDX_id,m$linlab)[m$uid==i]
  })


df <- df[sample(1:nrow(df)),]

p <- ggplot(df,aes(x=X1,y=X2,color=linlab))+
  geom_point()+
  coord_equal()+
  scale_x_continuous("UMAP1")+
  scale_y_continuous("UMAP2")+
  theme_classic()+
  scale_color_discrete("")
p

ggsave("figures/salehi_data_fitting/figures/umap_sel.png",width=4,height=4,units="in")



```

```{r}
source("utils/landscape_functions.R")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[x$r2>0,]
x <- x[!x$has_parents&!x$has_descendents&x$min_obs==5,]

x <- x[x$filenames%in%longest_cons(x$filenames),]
ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"
z <- pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  xii <- gen_all_neighbours(rownames(xi$xo))
  fii <- predict(xi$fit,xii)
  names(fii) <- apply(fii,1,paste,collapse=".")
  fi0 <- xi$xo$f_est
  names(fi0) <- rownames(xi$xo)
  c(fi0,fii)
})

combns <- expand.grid(a=1:length(z),b=1:length(z))

combns$cc <- sapply(1:nrow(combns), function(i){
  za <- z[[combns$a[i]]]
  zb <- z[[combns$b[i]]]
  za <- za[names(za)%in%names(zb)]
  if(length(za)==0) return(NaN)
  zb <- zb[names(za)]
  cc <- cor(za,zb)
  return(cc)
})

combns$n_overlap <- sapply(1:nrow(combns), function(i){
  za <- z[[combns$a[i]]]
  zb <- z[[combns$b[i]]]
  za <- za[names(za)%in%names(zb)]
  return(length(za))
})

combns$a_uid <- x$uid[combns$a]
combns$b_uid <- x$uid[combns$b]
combns$a_id <- sapply(combns$a_uid, function(i) {
  paste(m$PDX_id,m$linlab)[m$uid==i]
  })
combns$b_id <- sapply(combns$b_uid, function(i) {
  paste(m$PDX_id,m$linlab)[m$uid==i]
  })

p <- ggplot(combns,aes(x=a_id,y=b_id,fill=cc))+
  geom_raster()+
  scale_x_discrete("")+
  scale_y_discrete("")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  scale_fill_gradient2("pearson\ncoefficient")
p
ggsave("figures/salehi_data_fitting/figures/inter_lineage_correlations.png",width=7,height=6,units="in")
```
Correlatioin between fitness on purely treated/untreated.

So this surprising result happens because on the critical timepoint X4 where all the treated/untreated lines diverge, only 49 cells were in the sample. Then after that, apparently all new karyotypes appear... the relevant library datapoint is TNBC-SA609 timepoint	X4	library id A95720A. 


```{r}
source("utils/landscape_functions.R")

ff <- c( "SA609_X10_l_8_d1_0_d2_0.Rds",
"SA609UnBU_X7_l_6_d1_0_d2_0.Rds",
"SA609R2_X7_l_4_d1_0_d2_0.Rds",
"SA000_X7_l_3_d1_0_d2_0.Rds",
"SA535_CISPLATIN_CombinedT_X10_l_4_d1_0_d2_0.Rds",
"SA535_CISPLATIN_CombinedU_X9_l_5_d1_0_d2_0.Rds")

x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[x$filename%in%ff&x$min_obs==5,]

ff <- x$filenames
dir <- "data/salehi/alfak_fits/minobs_5/"
z <- pbapply::pblapply(ff,function(fi){
  xi <- readRDS(paste0(dir,fi))
  xii <- gen_all_neighbours(rownames(xi$xo))
  fii <- predict(xi$fit,xii)
  names(fii) <- apply(fii,1,paste,collapse=".")
  fi0 <- xi$xo$f_est
  names(fi0) <- rownames(xi$xo)
  c(fi0,fii)
})

combns <- expand.grid(a=1:length(z),b=1:length(z))

combns$cc <- sapply(1:nrow(combns), function(i){
  za <- z[[combns$a[i]]]
  zb <- z[[combns$b[i]]]
  za <- za[names(za)%in%names(zb)]
  if(length(za)==0) return(NaN)
  zb <- zb[names(za)]
  cc <- cor(za,zb)
  return(cc)
})

combns$n <- sapply(1:nrow(combns), function(i){
  za <- z[[combns$a[i]]]
  zb <- z[[combns$b[i]]]
  za <- za[names(za)%in%names(zb)]
  return(length(za))
})

combns$a <- x$uid[combns$a]
combns$b <- x$uid[combns$b]
combns$a_id <- sapply(combns$a, function(i) {
  paste(m$PDX_id,m$linlab)[m$uid==i]
  })
combns$b_id <- sapply(combns$b, function(i) {
  paste(m$PDX_id,m$linlab)[m$uid==i]
  })

pn <- ggplot(combns,aes(x=a_id,y=b_id,fill=n))+
  geom_raster()+
  scale_x_discrete("")+
  scale_y_discrete("")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  scale_fill_viridis_c("pearson\ncoefficient")
pn

p <- ggplot(combns,aes(x=a_id,y=b_id,fill=cc))+
  geom_raster()+
  scale_x_discrete("")+
  scale_y_discrete("")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  scale_fill_gradient2("pearson\ncoefficient")
p
ggsave("figures/salehi_data_fitting/figures/SA609_correlations.png",width=7,height=6,units="in")
```

```{r}
cnmat <- readRDS("data/salehi/chrom_level_cn.Rds")
dir <- "data/salehi/alfak_inputs_v2/"
source("utils/landscape_functions.R")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
x <- x[x$treatment_status%in%c("on","off")&x$min_obs==5&grepl("SA609",x$id)&!x$has_descendents,]
x <- x[x$filenames%in%longest_cons(x$filenames),c("id","filenames","r2")]

fi <- x$filenames[4]
y <- readRDS(paste0(dir,fi))$x
table(y[,1])
print(fi)
fi <- "SA609R2_X7_l_4_d1_0_d2_0.Rds"
id <- "SA609R2_X7_l_4_d1_0_d2_0"
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
lineage <- lineages[id]
```

Testing forward prediction accuracy:
```{r}
m <- read.csv("data/salehi/metadata.csv")
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
cnmat <- readRDS("data/salehi/chrom_level_cn.Rds")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
xf <- x[x$has_descendents&x$min_obs==5,]
ids <- as.character(sapply(xf$filenames,function(fi){head(unlist(strsplit(fi,split=".Rds")),1)}))
simdir <- "data/salehi/forward_sims_v2/minobs_5/"

tst <- which(ids%in%list.files(simdir))

df <- do.call(rbind,pbapply::pblapply(tst, function(i){
  #print(i)
  si <- paste0(simdir,ids[i],"/output/00000/")
  xs <- proc_sim(si,times=seq(0,300,150))$x
  vs <- do.call(rbind,lapply(rownames(xs),s2v))
  li <- lineages[[ids[i]]]
  
  ## sim output population vectors
  csx <- colSums(xs)
  xs <- t(xs)%*%vs
  for(k in 1:nrow(xs)) xs[k,] <- xs[k,]/csx[k]
  target_library_ids <- m$library_ids[m$uid==tail(li$ids,1)]
  target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
  x0 <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
  
  libid_exists <- sapply(li$dec1,function(idi){
    lidi <- m$library_ids[m$uid==idi]
    lidi%in%names(cnmat)
  })
  if(sum(libid_exists)==0) return(NULL)
  li$dec1 <- li$dec1[libid_exists]
  
  dfi <- do.call(rbind,lapply(1:length(li$dec1), function(j){
    target_library_ids <- m$library_ids[m$uid==li$dec1[j]]
    target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
    xd <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
    
    angles <- apply(xs,1,function(xsi){
      a <- xsi-x0
      b <- xd-x0
      ai <- getangle(a,b)
      
    })
    names(angles) <- paste0("a",names(angles))
    df <- cbind(xf[i,],t(angles))
    df$descendent <- li$dec1[j]
    df$declevel <- 1
    return(df)
  }))
  libid_exists <- sapply(li$dec2,function(idi){
    lidi <- m$library_ids[m$uid==idi]
    lidi%in%names(cnmat)
  })
  if(length(libid_exists)>0) li$dec2 <- li$dec2[libid_exists]
  if(length(li$dec2)>0){
    dfii <- do.call(rbind,lapply(1:length(li$dec2), function(j){
      target_library_ids <- m$library_ids[m$uid==li$dec2[j]]
      target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
      xd <- colMeans(do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]])))
      
      angles <- apply(xs,1,function(xsi){
        a <- xsi-x0
        b <- xd-x0
        ai <- getangle(a,b)
        
      })
      names(angles) <- paste0("a",names(angles))
      df <- cbind(xf[i,],t(angles))
      df$descendent <- li$dec1[j]
      df$declevel <- 2
      return(df)
    }))
    dfi <- rbind(dfi,dfii)
  }
  
  return(dfi)
  
}))

saveRDS(df,"figures/salehi_data_fitting/validation_summaries.Rds")

```

```{r}

wrap_res <- function(df){
  angle_data <- df[,paste0("a",seq(0,300,150))]
  df <- df[,!colnames(df)%in%paste0("a",seq(0,300,150))]
  df$angle <- angle_data$a150
  df$angle[df$declevel==2] <- angle_data$a300
  df$pos_r2 <- df$r2>0
  df$good_r2 <- df$r2>0.3
  return(df)
  
}

df <- wrap_res(readRDS("figures/salehi_data_fitting/validation_summaries.Rds"))
df$lab1 <- "R^2<0"
df$lab1[df$pos_r2] <- "R^2>0"
df$lab2 <- paste0("passage~",df$declevel)
p <- ggplot(df,aes(x=samples,y=angle))+
  facet_grid(cols=vars(lab1),rows=vars(lab2),labeller = label_parsed)+
  geom_violin()+
  geom_jitter(height=0,width=0.2)+
  geom_hline(yintercept = 90,color="red")+
  scale_x_discrete("sampled timepoints in fit")+
  scale_y_continuous("angle metric")
p
ggsave("figures/salehi_data_fitting/figures/forward_predictions.png",width=5,height=4,units="in")
```



Test ability to identify clones that have not yet emerged

```{r}

pred_unemerged <- function(fi){
  id <- head(unlist(strsplit(fi,split=".Rds")),1)
  l <- lineages[[id]]

  target_library_ids <- m$library_ids[m$uid%in%l$dec1]
  target_library_ids <- unlist(strsplit(target_library_ids,split=";"))
  x0 <- do.call(rbind,lapply(target_library_ids,function(tli) cnmat[[tli]]))
  x0 <- apply(x0,1,paste,collapse=".")
  x0 <- unique(x0)
  
  pop <- readRDS(paste0("data/salehi/alfak_inputs_v2/",fi))$x
  fit <- readRDS(paste0("data/salehi/alfak_fits/minobs_5/",fi))$fit
  candidates <- gen_all_neighbours(rownames(pop)[pop[,ncol(pop)]>0])
  f <- c(predict(fit,candidates))
  candidates <- apply(candidates,1,paste,collapse=".")
  names(f) <- candidates

  emerged <- x0[!x0%in%rownames(pop)]

  f_emerged <- f[names(f)%in%emerged]
  if(length(f_emerged)<2) return(data.frame(pval=NaN,delta_fitness=NaN))
  f_unemerged <- f[!names(f)%in%emerged]
  list(f_emerged=f_emerged,f_unemerged=f_unemerged)
}

m <- read.csv("data/salehi/metadata.csv")
lineages <- readRDS("figures/salehi_data_fitting/lineages.Rds")
cnmat <- readRDS("data/salehi/chrom_level_cn.Rds")
x <- readRDS("figures/salehi_data_fitting/fit_summaries.Rds")
xl <- x[x$has_descendents&x$min_obs==5&x$r2>0.3,]
xl <- xl[xl$filenames%in%longest_cons(xl$filenames),]

ff <- xl$filenames

pvals <- do.call(rbind,pbapply::pblapply(ff, function(fi){
  
  fitnesses <- pred_unemerged(fi)

  res <- t.test(fitnesses$f_unemerged,fitnesses$f_emerged)
  data.frame(pval=res$p.value,delta_fitness=diff(res$estimate),row.names = NULL)
}))

pvals$r2 <- xl$r2

p <- ggplot(pvals,aes(x=pval,y=delta_fitness))+
  geom_point()+
  scale_x_log10("T test P-value")+
  scale_y_continuous(expression(Delta~fitness))
p
ggsave("figures/salehi_data_fitting/figures/emerging_karyotype_prediction.png",width=3,height=3,units="in")


fi <- ff[2]

fitnesses <- pred_unemerged(fi)
fitnesses <- data.frame(f=c(fitnesses$f_emerged,fitnesses$f_unemerged),
                        id=c(rep("em",length(fitnesses$f_emerged)),
                             rep("un",length(fitnesses$f_unemerged)) ))

p <- ggplot(fitnesses,aes(x=id,y=f,group=id))+
  geom_violin()+
  scale_x_discrete("",labels=c("emerged","did not\nemerge"))+
  scale_y_continuous("fitness")
p
ggsave("figures/salehi_data_fitting/figures/emerging_karyotype_example.png",width=3,height=3,units="in")

```

It would be very interesting to compare how similar population evolution was in the instances where we have parallel evolution going on. 

The result is not as expected

```{r}
source("utils/comparison_functions.R")
x <- readRDS("data/salehi/chrom_level_cn.Rds")
m <- read.csv("data/salehi/metadata.csv")
m <- m[m$PDX_id=="SA609",]

nm <- table(m$parent)
nm <- names(nm)[nm>1]

l <- do.call(rbind,lapply(nm, function(ni) {
  children <- m$uid[m$parent==ni & !is.na(m$parent)]
  combos <- combn(1:length(children),2)
  cond_match <- apply(combos,2,function(ci){
    m$on_treatment[m$uid==children[ci[1]]]==m$on_treatment[m$uid==children[ci[2]]]
  })
  data.frame(parent=ni,child1=children[combos[1,]],
             child2=children[combos[2,]],cond_match)
}))

l <- cbind(l,data.frame(t(apply(l[,1:3],1,function(li){
  sapply(li, function(lij) m$library_ids[m$uid==lij])
}))))
colnames(l)[1:3] <- paste0("uid_",colnames(l)[1:3])



l$angles <- sapply(1:nrow(l), function(i){
  idpar <- unlist(strsplit(l$parent[i],split=";"))
  idc1 <- unlist(strsplit(l$child1[i],split=";"))
  idc2 <- unlist(strsplit(l$child2[i],split=";"))
  
  vpar <- colMeans(do.call(rbind,lapply(idpar,function(id) x[[id]])))
  vc1 <- colMeans(do.call(rbind,lapply(idc1,function(id) x[[id]])))-vpar
  vc2 <- colMeans(do.call(rbind,lapply(idc2,function(id) x[[id]])))-vpar
  
  getangle(vc1,vc2)
})


p <- ggplot(l,aes(x=angles))+
  facet_wrap(~cond_match)+
  geom_histogram(binwidth=10)
p

aggregate(l$angles,by=list(l$cond_match),mean)
```

